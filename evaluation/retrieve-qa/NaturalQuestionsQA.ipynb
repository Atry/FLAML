{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install flaml[retrievechat]~=2.0.0rc4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/FLAML/docs/reference/autogen/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models to use:  ['gpt-4']\n"
     ]
    }
   ],
   "source": [
    "from flaml import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\".config.local\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"gpt-4\",\n",
    "            \"gpt4\",\n",
    "            \"gpt-4-32k\",\n",
    "            \"gpt-4-32k-0314\",\n",
    "            \"gpt-35-turbo\",\n",
    "            \"gpt-3.5-turbo\",\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "assert len(config_list) > 0\n",
    "print(\"models to use: \", [config_list[i][\"model\"] for i in range(len(config_list))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct agents for RetrieveChat\n",
    "\n",
    "We start by initialzing the `RetrieveAssistantAgent` and `RetrieveUserProxyAgent`. The system message needs to be set to \"You are a helpful assistant.\" for RetrieveAssistantAgent. The detailed instructions are given in the user message. Later we will use the `RetrieveUserProxyAgent.generate_init_prompt` to combine the instructions and a math problem for an initial prompt to be sent to the LLM assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml.autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from flaml.autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "import chromadb\n",
    "\n",
    "# 1. create an RetrieveAssistantAgent instance named \"assistant\"\n",
    "assistant = RetrieveAssistantAgent(\n",
    "    name=\"assistant\", \n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    llm_config={\n",
    "        \"request_timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    ")\n",
    "\n",
    "# 2. create the RetrieveUserProxyAgent instance named \"ragproxyagent\"\n",
    "corpus_file = \"https://huggingface.co/datasets/thinkall/NaturalQuestionsQA/resolve/main/corpus.txt\"\n",
    "\n",
    "# Create a new collection for NaturalQuestions dataset\n",
    "ragproxyagent = RetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    retrieve_config={\n",
    "        \"docs_path\": corpus_file,\n",
    "        \"chunk_token_size\": 4900,\n",
    "        \"model\": config_list[0][\"model\"],\n",
    "        \"client\": chromadb.PersistentClient(path=\"/tmp/chromadb\"),\n",
    "        \"collection_name\": \"natural-questions\",\n",
    "        \"chunk_mode\": \"one_line\",\n",
    "        \"embedding_model\": \"all-MiniLM-L6-v2\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Questions QA\n",
    "\n",
    "Use RetrieveChat to answer questions for [NaturalQuestion](https://ai.google.com/research/NaturalQuestions) dataset.\n",
    "\n",
    "We'll first create a new document collection based on all the context corpus, then we select some questions and answer them with RetrieveChat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "--2023-08-09 14:44:36--  https://huggingface.co/datasets/thinkall/NaturalQuestionsQA/resolve/main/queries.jsonl\n",
      "Resolving huggingface.co (huggingface.co)... 13.32.50.53, 13.32.50.80, 13.32.50.129, ...\n",
      "Connecting to huggingface.co (huggingface.co)|13.32.50.53|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1380571 (1.3M) [text/plain]\n",
      "Saving to: ‘/tmp/chromadb/queries.jsonl’\n",
      "\n",
      "/tmp/chromadb/queri 100%[===================>]   1.32M  1.06MB/s    in 1.2s    \n",
      "\n",
      "2023-08-09 14:44:38 (1.06 MB/s) - ‘/tmp/chromadb/queries.jsonl’ saved [1380571/1380571]\n",
      "\n",
      "['what is non controlling interest on balance sheet', 'how many episodes are in chicago fire season 4', 'who sings love will keep us alive by the eagles', 'who is the leader of the ontario pc party', 'where did the last name keith come from']\n",
      "[[\"the portion of a subsidiary corporation 's stock that is not owned by the parent corporation\"], ['23'], ['Timothy B. Schmit'], ['Patrick Walter Brown'], ['from Keith in East Lothian , Scotland', \"from a nickname , derived from the Middle High German kīt , a word meaning `` sprout '' , `` offspring ''\"]]\n",
      "Number of questions: 6775\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "queries_file = \"https://huggingface.co/datasets/thinkall/NaturalQuestionsQA/resolve/main/queries.jsonl\"\n",
    "!wget -O /tmp/chromadb/queries.jsonl $queries_file\n",
    "queries = [json.loads(line) for line in open(\"/tmp/chromadb/queries.jsonl\").readlines() if line]\n",
    "questions = [q[\"text\"] for q in queries]\n",
    "answers = [q[\"metadata\"][\"answer\"] for q in queries]\n",
    "print(questions[:5])\n",
    "print(answers[:5])\n",
    "print(\"Number of questions:\", len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO \n",
    "import sys\n",
    "\n",
    "class Capturing(list):\n",
    "    def __enter__(self):\n",
    "        self._stdout = sys.stdout\n",
    "        sys.stdout = self._stringio = StringIO()\n",
    "        return self\n",
    "    def __exit__(self, *args):\n",
    "        self.extend(self._stringio.getvalue().splitlines())\n",
    "        del self._stringio    # free up some memory\n",
    "        sys.stdout = self._stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:45:33] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:45:49] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:46:05] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:46:21] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:46:35] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:46:47] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:47:00] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:47:13] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:47:25] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:47:40] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:47:57] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:48:12] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:48:27] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:48:41] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:48:55] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:49:06] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:49:49] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:50:05] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:50:23] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:50:40] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:51:00] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:51:47] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:52:02] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:52:20] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:52:35] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:52:50] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:53:04] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:53:27] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:53:39] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:53:52] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:54:07] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:54:25] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:54:41] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:54:59] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:55:14] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:55:28] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:55:41] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:55:56] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:56:11] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:56:24] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:56:38] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:56:54] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:57:10] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:57:23] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:57:35] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:57:49] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:58:04] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:58:16] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:58:31] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:58:44] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:58:56] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:59:11] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 14:59:58] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:00:12] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:00:27] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:00:40] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:00:53] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:01:05] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:01:22] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:01:36] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:01:51] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:02:06] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:02:24] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:02:41] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:02:53] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:03:10] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:03:25] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:03:54] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:04:14] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:04:28] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:04:41] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:04:55] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:05:07] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:05:22] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:05:36] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:05:53] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:06:11] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:06:39] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:06:58] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:07:11] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:07:37] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:07:52] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:08:09] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:08:23] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:08:37] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:08:52] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:09:07] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:09:22] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:09:48] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:10:02] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:10:16] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:10:32] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:10:47] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:11:00] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:11:14] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:11:26] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:11:39] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:11:56] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:12:09] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.autogen.oai.completion: 08-09 15:12:23] {234} INFO - retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.autogen.oai.completion:retrying in 10 seconds...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lijiang1/code/FLAML1/flaml/autogen/oai/completion.py\", line 204, in _get_response\n",
      "    response = openai_completion.create(**config)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 298, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 700, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/home/lijiang1/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py\", line 763, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "The response was filtered due to the prompt triggering Azure OpenAI’s content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m assistant\u001b[39m.\u001b[39mreset()\n\u001b[1;32m      4\u001b[0m \u001b[39mwith\u001b[39;00m Capturing() \u001b[39mas\u001b[39;00m print_output:\n\u001b[0;32m----> 5\u001b[0m     ragproxyagent\u001b[39m.\u001b[39;49minitiate_chat(assistant, problem\u001b[39m=\u001b[39;49mqa_problem, n_results\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m retrieve_answers\u001b[39m.\u001b[39mappend(print_output[\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m])\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/agentchat/responsive_agent.py:487\u001b[0m, in \u001b[0;36mResponsiveAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, **context)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \n\u001b[1;32m    476\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[0;32m--> 487\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient)\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/agentchat/responsive_agent.py:319\u001b[0m, in \u001b[0;36mResponsiveAgent.send\u001b[0;34m(self, message, recipient, request_reply)\u001b[0m\n\u001b[1;32m    317\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[1;32m    318\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[0;32m--> 319\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply)\n\u001b[1;32m    320\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    322\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    323\u001b[0m     )\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/agentchat/responsive_agent.py:434\u001b[0m, in \u001b[0;36mResponsiveAgent.receive\u001b[0;34m(self, message, sender, request_reply)\u001b[0m\n\u001b[1;32m    432\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_reply(sender\u001b[39m=\u001b[39msender)\n\u001b[1;32m    433\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 434\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(reply, sender)\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/agentchat/responsive_agent.py:319\u001b[0m, in \u001b[0;36mResponsiveAgent.send\u001b[0;34m(self, message, recipient, request_reply)\u001b[0m\n\u001b[1;32m    317\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[1;32m    318\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[0;32m--> 319\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply)\n\u001b[1;32m    320\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    322\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    323\u001b[0m     )\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/agentchat/responsive_agent.py:432\u001b[0m, in \u001b[0;36mResponsiveAgent.receive\u001b[0;34m(self, message, sender, request_reply)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    431\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 432\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(sender\u001b[39m=\u001b[39;49msender)\n\u001b[1;32m    433\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender)\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/agentchat/responsive_agent.py:712\u001b[0m, in \u001b[0;36mResponsiveAgent.generate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[0;32m--> 712\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\n\u001b[1;32m    713\u001b[0m         \u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, context\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m    714\u001b[0m     )\n\u001b[1;32m    715\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[1;32m    716\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/agentchat/contrib/retrieve_user_proxy_agent.py:174\u001b[0m, in \u001b[0;36mRetrieveUserProxyAgent._generate_retrieve_user_reply\u001b[0;34m(self, messages, sender, context)\u001b[0m\n\u001b[1;32m    172\u001b[0m     sender\u001b[39m.\u001b[39mclear_history()\n\u001b[1;32m    173\u001b[0m     doc_contents \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_context(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_results)\n\u001b[0;32m--> 174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_message(doc_contents), sender)\n\u001b[1;32m    175\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/agentchat/responsive_agent.py:319\u001b[0m, in \u001b[0;36mResponsiveAgent.send\u001b[0;34m(self, message, recipient, request_reply)\u001b[0m\n\u001b[1;32m    317\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[1;32m    318\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[0;32m--> 319\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply)\n\u001b[1;32m    320\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    322\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    323\u001b[0m     )\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/agentchat/responsive_agent.py:434\u001b[0m, in \u001b[0;36mResponsiveAgent.receive\u001b[0;34m(self, message, sender, request_reply)\u001b[0m\n\u001b[1;32m    432\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_reply(sender\u001b[39m=\u001b[39msender)\n\u001b[1;32m    433\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 434\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(reply, sender)\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/agentchat/responsive_agent.py:319\u001b[0m, in \u001b[0;36mResponsiveAgent.send\u001b[0;34m(self, message, recipient, request_reply)\u001b[0m\n\u001b[1;32m    317\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[1;32m    318\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[0;32m--> 319\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply)\n\u001b[1;32m    320\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    322\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    323\u001b[0m     )\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/agentchat/responsive_agent.py:432\u001b[0m, in \u001b[0;36mResponsiveAgent.receive\u001b[0;34m(self, message, sender, request_reply)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    431\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 432\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(sender\u001b[39m=\u001b[39;49msender)\n\u001b[1;32m    433\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender)\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/agentchat/responsive_agent.py:712\u001b[0m, in \u001b[0;36mResponsiveAgent.generate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[0;32m--> 712\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\n\u001b[1;32m    713\u001b[0m         \u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, context\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m    714\u001b[0m     )\n\u001b[1;32m    715\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[1;32m    716\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/agentchat/contrib/retrieve_user_proxy_agent.py:174\u001b[0m, in \u001b[0;36mRetrieveUserProxyAgent._generate_retrieve_user_reply\u001b[0;34m(self, messages, sender, context)\u001b[0m\n\u001b[1;32m    172\u001b[0m     sender\u001b[39m.\u001b[39mclear_history()\n\u001b[1;32m    173\u001b[0m     doc_contents \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_context(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_results)\n\u001b[0;32m--> 174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_message(doc_contents), sender)\n\u001b[1;32m    175\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/agentchat/responsive_agent.py:319\u001b[0m, in \u001b[0;36mResponsiveAgent.send\u001b[0;34m(self, message, recipient, request_reply)\u001b[0m\n\u001b[1;32m    317\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[1;32m    318\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[0;32m--> 319\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply)\n\u001b[1;32m    320\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    322\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    323\u001b[0m     )\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/agentchat/responsive_agent.py:432\u001b[0m, in \u001b[0;36mResponsiveAgent.receive\u001b[0;34m(self, message, sender, request_reply)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    431\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 432\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(sender\u001b[39m=\u001b[39;49msender)\n\u001b[1;32m    433\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender)\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/agentchat/responsive_agent.py:712\u001b[0m, in \u001b[0;36mResponsiveAgent.generate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[0;32m--> 712\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\n\u001b[1;32m    713\u001b[0m         \u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, context\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m    714\u001b[0m     )\n\u001b[1;32m    715\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[1;32m    716\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/agentchat/responsive_agent.py:555\u001b[0m, in \u001b[0;36mResponsiveAgent.generate_oai_reply\u001b[0;34m(self, messages, sender, context)\u001b[0m\n\u001b[1;32m    552\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_oai_messages[sender]\n\u001b[1;32m    554\u001b[0m \u001b[39m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[0;32m--> 555\u001b[0m response \u001b[39m=\u001b[39m oai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m    556\u001b[0m     context\u001b[39m=\u001b[39;49mmessages[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m), messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_oai_system_message \u001b[39m+\u001b[39;49m messages, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mllm_config\n\u001b[1;32m    557\u001b[0m )\n\u001b[1;32m    558\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m, oai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mextract_text_or_function_call(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/oai/completion.py:764\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[1;32m    762\u001b[0m     base_config[\u001b[39m\"\u001b[39m\u001b[39mretry_timeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    763\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 764\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m    765\u001b[0m         context,\n\u001b[1;32m    766\u001b[0m         use_cache,\n\u001b[1;32m    767\u001b[0m         raise_on_ratelimit_or_timeout\u001b[39m=\u001b[39;49mi \u001b[39m<\u001b[39;49m last \u001b[39mor\u001b[39;49;00m raise_on_ratelimit_or_timeout,\n\u001b[1;32m    768\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbase_config,\n\u001b[1;32m    769\u001b[0m     )\n\u001b[1;32m    770\u001b[0m     \u001b[39mif\u001b[39;00m response \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m    771\u001b[0m         \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/oai/completion.py:795\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[39mwith\u001b[39;00m diskcache\u001b[39m.\u001b[39mCache(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcache_path) \u001b[39mas\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_cache:\n\u001b[1;32m    794\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mset_cache(seed)\n\u001b[0;32m--> 795\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_response(params, raise_on_ratelimit_or_timeout\u001b[39m=\u001b[39;49mraise_on_ratelimit_or_timeout)\n",
      "File \u001b[0;32m~/code/FLAML1/flaml/autogen/oai/completion.py:204\u001b[0m, in \u001b[0;36mCompletion._get_response\u001b[0;34m(cls, config, raise_on_ratelimit_or_timeout, use_cache)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mrequest_timeout\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config:\n\u001b[0;32m--> 204\u001b[0m         response \u001b[39m=\u001b[39m openai_completion\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig)\n\u001b[1;32m    205\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m         response \u001b[39m=\u001b[39m openai_completion\u001b[39m.\u001b[39mcreate(request_timeout\u001b[39m=\u001b[39mrequest_timeout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig)\n",
      "File \u001b[0;32m~/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/flaml-oss/lib/python3.8/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: The response was filtered due to the prompt triggering Azure OpenAI’s content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766"
     ]
    }
   ],
   "source": [
    "retrieve_answers = []\n",
    "for qa_problem in questions[:200]:\n",
    "    assistant.reset()\n",
    "    with Capturing() as print_output:\n",
    "        ragproxyagent.initiate_chat(assistant, problem=qa_problem, n_results=3)\n",
    "    retrieve_answers.append(print_output[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Non-controlling interest, also known as minority interest, on a balance sheet refers to the portion of a subsidiary corporation's stock that is not owned by the parent corporation. It often makes up less than 50% of outstanding shares, as ownership above that threshold would generally cause the company to cease being a subsidiary.\", 'The fourth season of Chicago Fire contains 23 episodes.', '\"Love Will Keep Us Alive\" by the Eagles is sung by their bassist, Timothy B. Schmit.', 'Patrick Brown is the leader of the Ontario PC Party.', 'The last name Keith is of Scottish origin, derived from a place name in East Lothian, Scotland.']\n",
      "len(retrieve_answers): 145\n"
     ]
    }
   ],
   "source": [
    "print(retrieve_answers[:5])\n",
    "print(\"len(retrieve_answers):\", len(retrieve_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://qa.fastforwardlabs.com/no%20answer/null%20threshold/bert/distilbert/exact%20match/f1/robust%20predictions/2020/06/09/Evaluating_BERT_on_SQuAD.html#F1\n",
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    import string, re\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1_recall(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "    \n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens), int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    \n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0, 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec), rec\n",
    "\n",
    "def get_gold_answers(example):\n",
    "    \"\"\"helper function that retrieves all possible true answers from a squad2.0 example\"\"\"\n",
    "    \n",
    "    gold_answers = [answer[\"text\"] for answer in example.answers if answer[\"text\"]]\n",
    "\n",
    "    # if gold_answers doesn't exist it's because this is a negative example - \n",
    "    # the only correct answer is an empty string\n",
    "    if not gold_answers:\n",
    "        gold_answers = [\"\"]\n",
    "        \n",
    "    return gold_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is non controlling interest on balance sheet\n",
      "Prediction: Non-controlling interest, also known as minority interest, on a balance sheet refers to the portion of a subsidiary corporation's stock that is not owned by the parent corporation. It often makes up less than 50% of outstanding shares, as ownership above that threshold would generally cause the company to cease being a subsidiary.\n",
      "True Answers: [\"the portion of a subsidiary corporation 's stock that is not owned by the parent corporation\"]\n",
      "EM: 0 \t F1: 0.36666666666666675 \t Recall: 0.8461538461538461\n",
      "Question: what is non controlling interest on balance sheet\n",
      "Prediction: The three elves who got rings in Tolkien's legendarium are Galadriel, Gil-galad, and Círdan.\n",
      "True Answers: ['Gil - galad', 'Círdan', 'Galadriel']\n",
      "EM: 0 \t F1: 0.14285714285714288 \t Recall: 1.0\n",
      "Question: what is non controlling interest on balance sheet\n",
      "Prediction: Patrick Brown is the leader of the Ontario PC Party.\n",
      "True Answers: ['Patrick Brown']\n",
      "EM: 0 \t F1: 0.4 \t Recall: 1.0\n",
      "Question: what is non controlling interest on balance sheet\n",
      "Prediction: The latest season of Keeping Up with the Kardashians is not mentioned in the provided context. Please update the context or provide more information.\n",
      "True Answers: ['fourteen']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: what is non controlling interest on balance sheet\n",
      "Prediction: The meaning of the name Comanche is not directly related to the provided context. The Comanche are a Native American tribe whose name comes from the Ute word \"Kimantsi,\" meaning \"enemy\" or \"stranger.\"\n",
      "True Answers: [\"`` Comanche '' is from the Ute name for them , kɨmantsi ( enemy )\"]\n",
      "EM: 0 \t F1: 0.3333333333333333 \t Recall: 0.6666666666666666\n",
      "Question: what is non controlling interest on balance sheet\n",
      "Prediction: The Eleventh Amendment was proposed by Congress in response to the U.S. Supreme Court's decision in Chisholm v. Georgia (1793), which allowed citizens of one state to sue another state in federal court. The Eleventh Amendment limited the jurisdiction of federal courts by preventing them from hearing cases against a state in which the state is sued by citizens of another state or a foreign nation.\n",
      "True Answers: [\"the Supreme Court 's ruling in Chisholm v. Georgia , 2 U.S. 419 ( 1793 )\"]\n",
      "EM: 0 \t F1: 0.22535211267605634 \t Recall: 0.6666666666666666\n",
      "Question: what is non controlling interest on balance sheet\n",
      "Prediction: From my available information, the Royal Society for the Protection of Birds (RSPB) has over 1 million members.\n",
      "True Answers: ['more than a million members ( including 195,000 youth members )']\n",
      "EM: 0 \t F1: 0.16666666666666666 \t Recall: 0.25\n",
      "Question: what is non controlling interest on balance sheet\n",
      "Prediction: The movie \"Jeremiah Johnson\" was filmed in various locations in Utah, including Ashley National Forest, Uinta Mountains, and the Zion National Park.\n",
      "True Answers: ['in nearly 100 locations across Utah , including : Mount Timpanogos , Ashley National Forest , Leeds , Snow Canyon State Park , St. George , Sundance Resort , Uinta National Forest , Wasatch - Cache National Forest , and Zion National Park']\n",
      "EM: 0 \t F1: 0.42307692307692313 \t Recall: 0.34375\n",
      "Question: what is non controlling interest on balance sheet\n",
      "Prediction: In Canada, there is no fixed term for a prime minister. They can stay in office as long as their party maintains the confidence of the House of Commons and they remain the leader of the party.\n",
      "True Answers: ['four years']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: what is non controlling interest on balance sheet\n",
      "Prediction: Domhnall Gleeson plays General Hux in The Last Jedi.\n",
      "True Answers: ['Domhnall Gleeson']\n",
      "EM: 0 \t F1: 0.4 \t Recall: 1.0\n",
      "Question: what is non controlling interest on balance sheet\n",
      "Prediction: Isle of Dogs was released in the US on March 23, 2018.\n",
      "True Answers: ['March 23 , 2018']\n",
      "EM: 0 \t F1: 0.42857142857142855 \t Recall: 1.0\n",
      "Question: what is non controlling interest on balance sheet\n",
      "Prediction: The flag you are referring to is the United States flag, which was placed on the moon during the Apollo 11 mission in 1969.\n",
      "True Answers: ['Sea of Tranquility']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: what is non controlling interest on balance sheet\n",
      "Prediction: The remake of \"True Grit\" (2010) starred Jeff Bridges as Rooster Cogburn, Hailee Steinfeld as Mattie Ross, Matt Damon as LaBoeuf, and Josh Brolin as Tom Chaney.\n",
      "True Answers: ['Hailee Steinfeld', 'Jeff Bridges', 'Matt Damon', 'Josh Brolin', 'Barry Pepper']\n",
      "EM: 0 \t F1: 0.14285714285714288 \t Recall: 1.0\n",
      "Question: what is non controlling interest on balance sheet\n",
      "Prediction: The Price is Right first aired in 1956.\n",
      "True Answers: ['1956']\n",
      "EM: 0 \t F1: 0.25 \t Recall: 1.0\n",
      "Question: what is non controlling interest on balance sheet\n",
      "Prediction: Timbuktu under the Mali Empire is best described as a prosperous and significant cultural, educational, and trade center.\n",
      "True Answers: ['a place of trade , entertainment , and education']\n",
      "EM: 0 \t F1: 0.18181818181818182 \t Recall: 0.3333333333333333\n",
      "=======================================\n",
      "Average EM: 0.0\n",
      "Average F1: 0.17113575754109359\n",
      "Average Recall: 0.5484944253290597\n"
     ]
    }
   ],
   "source": [
    "all_em_scores = []\n",
    "all_f1_scores = []\n",
    "all_recall_scores = []\n",
    "for i in range(len(retrieve_answers)):\n",
    "    prediction = retrieve_answers[i]\n",
    "    gold_answers = answers[i]\n",
    "\n",
    "    em_score = max((compute_exact_match(prediction, answer)) for answer in gold_answers)\n",
    "    f1_score = max((compute_f1_recall(prediction, answer)[0]) for answer in gold_answers)\n",
    "    recall_score = max((compute_f1_recall(prediction, answer)[1]) for answer in gold_answers)\n",
    "\n",
    "    all_em_scores.append(em_score)\n",
    "    all_f1_scores.append(f1_score)\n",
    "    all_recall_scores.append(recall_score)\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Question: {questions[0]}\")\n",
    "        print(f\"Prediction: {prediction}\")\n",
    "        print(f\"True Answers: {gold_answers}\")\n",
    "        print(f\"EM: {em_score} \\t F1: {f1_score} \\t Recall: {recall_score}\")\n",
    "\n",
    "print(\"=======================================\")\n",
    "print(f\"Average EM: {sum(all_em_scores) / len(all_em_scores)}\")\n",
    "print(f\"Average F1: {sum(all_f1_scores) / len(all_f1_scores)}\")\n",
    "print(f\"Average Recall: {sum(all_recall_scores) / len(all_recall_scores)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaml_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
