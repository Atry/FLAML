{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install flaml[retrievechat]~=2.0.0rc5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/FLAML/docs/reference/autogen/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models to use:  ['gpt-4']\n"
     ]
    }
   ],
   "source": [
    "from flaml import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\".config.local\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"gpt-4\",\n",
    "            \"gpt4\",\n",
    "            \"gpt-4-32k\",\n",
    "            \"gpt-4-32k-0314\",\n",
    "            \"gpt-35-turbo\",\n",
    "            \"gpt-3.5-turbo\",\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "assert len(config_list) > 0\n",
    "print(\"models to use: \", [config_list[i][\"model\"] for i in range(len(config_list))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct agents for RetrieveChat\n",
    "\n",
    "We start by initialzing the `RetrieveAssistantAgent` and `RetrieveUserProxyAgent`. The system message needs to be set to \"You are a helpful assistant.\" for RetrieveAssistantAgent. The detailed instructions are given in the user message. Later we will use the `RetrieveUserProxyAgent.generate_init_prompt` to combine the instructions and a math problem for an initial prompt to be sent to the LLM assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml.autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from flaml.autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "import chromadb\n",
    "\n",
    "# 1. create an RetrieveAssistantAgent instance named \"assistant\"\n",
    "assistant = RetrieveAssistantAgent(\n",
    "    name=\"assistant\", \n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    llm_config={\n",
    "        \"request_timeout\": 600,\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    ")\n",
    "\n",
    "# 2. create the RetrieveUserProxyAgent instance named \"ragproxyagent\"\n",
    "corpus_file = \"https://huggingface.co/datasets/thinkall/NaturalQuestionsQA/resolve/main/corpus.txt\"\n",
    "\n",
    "# Create a new collection for NaturalQuestions dataset\n",
    "ragproxyagent = RetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    retrieve_config={\n",
    "        \"docs_path\": corpus_file,\n",
    "        \"chunk_token_size\": 4900,\n",
    "        \"model\": config_list[0][\"model\"],\n",
    "        \"client\": chromadb.PersistentClient(path=\"/tmp/chromadb\"),\n",
    "        \"collection_name\": \"natural-questions\",\n",
    "        \"chunk_mode\": \"one_line\",\n",
    "        \"embedding_model\": \"all-MiniLM-L6-v2\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Questions QA\n",
    "\n",
    "Use RetrieveChat to answer questions for [NaturalQuestion](https://ai.google.com/research/NaturalQuestions) dataset.\n",
    "\n",
    "We'll first create a new document collection based on all the context corpus, then we select some questions and answer them with RetrieveChat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-10 19:31:54--  https://huggingface.co/datasets/thinkall/NaturalQuestionsQA/resolve/main/queries.jsonl\n",
      "Resolving huggingface.co (huggingface.co)... 143.204.126.33, 143.204.126.6, 143.204.126.36, ...\n",
      "Connecting to huggingface.co (huggingface.co)|143.204.126.33|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1380571 (1.3M) [text/plain]\n",
      "Saving to: ‘/tmp/chromadb/queries.jsonl’\n",
      "\n",
      "/tmp/chromadb/queri 100%[===================>]   1.32M  1.32MB/s    in 1.0s    \n",
      "\n",
      "2023-08-10 19:31:55 (1.32 MB/s) - ‘/tmp/chromadb/queries.jsonl’ saved [1380571/1380571]\n",
      "\n",
      "['what is non controlling interest on balance sheet', 'how many episodes are in chicago fire season 4', 'who sings love will keep us alive by the eagles', 'who is the leader of the ontario pc party', 'where did the last name keith come from']\n",
      "[[\"the portion of a subsidiary corporation 's stock that is not owned by the parent corporation\"], ['23'], ['Timothy B. Schmit'], ['Patrick Walter Brown'], ['from Keith in East Lothian , Scotland', \"from a nickname , derived from the Middle High German kīt , a word meaning `` sprout '' , `` offspring ''\"]]\n",
      "Number of questions: 6775\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "queries_file = \"https://huggingface.co/datasets/thinkall/NaturalQuestionsQA/resolve/main/queries.jsonl\"\n",
    "!wget -O /tmp/chromadb/queries.jsonl $queries_file\n",
    "queries = [json.loads(line) for line in open(\"/tmp/chromadb/queries.jsonl\").readlines() if line]\n",
    "questions = [q[\"text\"] for q in queries]\n",
    "answers = [q[\"metadata\"][\"answer\"] for q in queries]\n",
    "print(questions[:5])\n",
    "print(answers[:5])\n",
    "print(\"Number of questions:\", len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO \n",
    "import sys\n",
    "\n",
    "class Capturing(list):\n",
    "    def __enter__(self):\n",
    "        self._stdout = sys.stdout\n",
    "        sys.stdout = self._stringio = StringIO()\n",
    "        return self\n",
    "    def __exit__(self, *args):\n",
    "        self.extend(self._stringio.getvalue().splitlines())\n",
    "        del self._stringio    # free up some memory\n",
    "        sys.stdout = self._stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_answers = []\n",
    "for qa_problem in questions[:200]:\n",
    "    assistant.reset()\n",
    "    with Capturing() as print_output:\n",
    "        ragproxyagent.initiate_chat(assistant, problem=qa_problem, n_results=3)\n",
    "    retrieve_answers.append(print_output[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Non-controlling interest (or minority interest) on a balance sheet refers to the portion of a subsidiary corporation's stock that is not owned by the parent corporation. It represents the equity owned by minority shareholders and is usually less than 50% of the outstanding shares.\", 'The fourth season of Chicago Fire contains 23 episodes.', 'Timothy B. Schmit sings \"Love Will Keep Us Alive\" by the Eagles.', 'The leader of the Ontario PC Party is Patrick Brown.', 'The last name Keith has several origins. It can be derived from Keith in East Lothian, Scotland, or it can originate from a nickname, derived from the Middle High German word \"kīt,\" which means \"sprout\" or \"offspring.\"']\n",
      "len(retrieve_answers): 200\n"
     ]
    }
   ],
   "source": [
    "print(retrieve_answers[:5])\n",
    "print(\"len(retrieve_answers):\", len(retrieve_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://qa.fastforwardlabs.com/no%20answer/null%20threshold/bert/distilbert/exact%20match/f1/robust%20predictions/2020/06/09/Evaluating_BERT_on_SQuAD.html#F1\n",
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    import string, re\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1_recall(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "    \n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens), int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    \n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0, 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec), rec\n",
    "\n",
    "def get_gold_answers(example):\n",
    "    \"\"\"helper function that retrieves all possible true answers from a squad2.0 example\"\"\"\n",
    "    \n",
    "    gold_answers = [answer[\"text\"] for answer in example.answers if answer[\"text\"]]\n",
    "\n",
    "    # if gold_answers doesn't exist it's because this is a negative example - \n",
    "    # the only correct answer is an empty string\n",
    "    if not gold_answers:\n",
    "        gold_answers = [\"\"]\n",
    "        \n",
    "    return gold_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is non controlling interest on balance sheet\n",
      "Prediction: Non-controlling interest (or minority interest) on a balance sheet refers to the portion of a subsidiary corporation's stock that is not owned by the parent corporation. It represents the equity owned by minority shareholders and is usually less than 50% of the outstanding shares.\n",
      "True Answers: [\"the portion of a subsidiary corporation 's stock that is not owned by the parent corporation\"]\n",
      "EM: 0 \t F1: 0.4313725490196079 \t Recall: 0.8461538461538461\n",
      "Question: converting stereo signal to mono signal is called\n",
      "Prediction: Converting a stereo signal to a mono signal is called creating a dual mono signal.\n",
      "True Answers: ['Panning']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: who were the three elves who got rings\n",
      "Prediction: The three elves who received the rings were Círdan, who received Narya; Gil-galad, who received Vilya; and Galadriel, who received Nenya.\n",
      "True Answers: ['Gil - galad', 'Círdan', 'Galadriel']\n",
      "EM: 0 \t F1: 0.1 \t Recall: 1.0\n",
      "Question: in order to prove disparate impact you first must establish\n",
      "Prediction: In order to prove disparate impact, you first must establish that a seemingly neutral policy or practice disproportionately affects a protected group of people, resulting in an adverse impact. This may involve analyzing statistical evidence to demonstrate the disparate impact.\n",
      "True Answers: ['practices in employment , housing , and other areas that adversely affect one group of people of a protected characteristic more than another , even though rules applied by employers or landlords are formally neutral']\n",
      "EM: 0 \t F1: 0.2388059701492537 \t Recall: 0.25806451612903225\n",
      "Question: who is the leader of the ontario pc party\n",
      "Prediction: The leader of the Ontario PC Party is Patrick Brown.\n",
      "True Answers: ['Patrick Brown']\n",
      "EM: 0 \t F1: 0.4 \t Recall: 1.0\n",
      "Question: how many seasons of prison break are on netflix\n",
      "Prediction: There are 5 seasons of Prison Break available on Netflix.\n",
      "True Answers: ['five']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: when did they stop cigarette advertising on television\n",
      "Prediction: Cigarette advertising on television was banned on January 2, 1971, due to the Public Health Cigarette Smoking Act.\n",
      "True Answers: ['1970']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: latest season on keeping up with the kardashians\n",
      "Prediction: As of December 10, 2017, the latest season of Keeping Up with the Kardashians is Season 14.\n",
      "True Answers: ['fourteen']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: when did the us take over wake island\n",
      "Prediction: The US formally took possession of Wake Island on January 17, 1899, under orders from President William McKinley and Commander Edward D. Taussig of USS Bennington.\n",
      "True Answers: ['July 4 , 1898']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: who has the oldest team in the nba\n",
      "Prediction: \n",
      "True Answers: ['New York Knickerbockers']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: who were farmers who kept a small portion of their crops & gave the rest to the landowners\n",
      "Prediction: The farmers you are referring to are sharecroppers. They kept a small portion of their crops and gave the rest to the landowners as a form of rent or repayment for using the land.\n",
      "True Answers: ['Sharecropping']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: what is the meaning of the name comanche\n",
      "Prediction: The meaning of the name Comanche is derived from the Ute name for them, kɨmantsi, which means \"enemy\".\n",
      "True Answers: [\"`` Comanche '' is from the Ute name for them , kɨmantsi ( enemy )\"]\n",
      "EM: 0 \t F1: 0.7499999999999999 \t Recall: 1.0\n",
      "Question: what event provoked congress to propose the eleventh amendment and the states to ratify it\n",
      "Prediction: The event that provoked Congress to propose the Eleventh Amendment and the states to ratify it was the U.S. Supreme Court's decision in Chisholm v. Georgia, 2 U.S. 419 (1793).\n",
      "True Answers: [\"the Supreme Court 's ruling in Chisholm v. Georgia , 2 U.S. 419 ( 1793 )\"]\n",
      "EM: 0 \t F1: 0.4736842105263157 \t Recall: 0.75\n",
      "Question: who plays timon in lion king on broadway\n",
      "Prediction: Nathan Lane originally played the role of Timon in the Broadway production of The Lion King. However, various actors have portrayed Timon since then, as the cast has changed over time.\n",
      "True Answers: ['Max Casella']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: who is edmund on days of our lives\n",
      "Prediction: Edmund is not mentioned in the context provided. Please provide more context to answer the question. \n",
      "True Answers: ['Adam Caine']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: royal society for the protection of birds number of members\n",
      "Prediction: The RSPB has more than a million members, including 195,000 youth members.\n",
      "True Answers: ['more than a million members ( including 195,000 youth members )']\n",
      "EM: 0 \t F1: 0.7777777777777777 \t Recall: 0.875\n",
      "Question: where was the movie jeremiah johnson filmed at\n",
      "Prediction: Jeremiah Johnson was filmed primarily in Utah, USA.\n",
      "True Answers: ['in nearly 100 locations across Utah , including : Mount Timpanogos , Ashley National Forest , Leeds , Snow Canyon State Park , St. George , Sundance Resort , Uinta National Forest , Wasatch - Cache National Forest , and Zion National Park']\n",
      "EM: 0 \t F1: 0.1 \t Recall: 0.0625\n",
      "Question: what is the meaning of the name comanche\n",
      "Prediction: The meaning of the name Comanche is derived from the Ute name for them, kɨmantsi, which means \"enemy\".\n",
      "True Answers: ['a Native American nation from the Great Plains']\n",
      "EM: 0 \t F1: 0.09523809523809522 \t Recall: 0.16666666666666666\n",
      "Question: when was theme from a summer place released\n",
      "Prediction: Theme from A Summer Place was released in September 1959.\n",
      "True Answers: ['1960']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: what degree is a crock pot on low\n",
      "Prediction: The context provided does not specifically mention the temperature for a crock pot on low setting. Please provide more context or information about crock pots.\n",
      "True Answers: ['71 -- 74 ° C ( 160 -- 165 ° F )']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: who has scored the most tries in rugby union\n",
      "Prediction: \n",
      "True Answers: ['Daisuke Ohata']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: how long prime minister stay in office canada\n",
      "Prediction: The Canadian prime minister does not have a fixed term. They remain in office until they resign, are dismissed, or die. However, the term of a majority government is limited to four years, with elections set as the third Monday in October of the fourth calendar year after the previous polling date.\n",
      "True Answers: ['four years']\n",
      "EM: 0 \t F1: 0.0851063829787234 \t Recall: 1.0\n",
      "Question: when did you have to have a driver 's license\n",
      "Prediction: Mandatory licensing for drivers came into force on 1 January 1904 after the Motor Car Act 1903 received royal assent in the United Kingdom.\n",
      "True Answers: ['to operate one or more types of motorized vehicles , such as a motorcycle , car , truck , or bus on a public road']\n",
      "EM: 0 \t F1: 0.0975609756097561 \t Recall: 0.10526315789473684\n",
      "Question: who plays general hux in the last jedi\n",
      "Prediction: Domhnall Gleeson plays General Hux in The Last Jedi.\n",
      "True Answers: ['Domhnall Gleeson']\n",
      "EM: 0 \t F1: 0.4 \t Recall: 1.0\n",
      "Question: when does isle of dogs come out in us\n",
      "Prediction: Isle of Dogs began a limited release in the United States on March 23, 2018, and had a wide release on April 13, 2018.\n",
      "True Answers: ['March 23 , 2018']\n",
      "EM: 0 \t F1: 0.25 \t Recall: 1.0\n",
      "Question: when does grey 's anatomy come back on in march\n",
      "Prediction: \n",
      "True Answers: ['March 1 , 2018']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: where was the flag placed on the moon\n",
      "Prediction: The flag was placed on the Moon at the site of the Apollo 11 mission's landing, the Sea of Tranquility.\n",
      "True Answers: ['Sea of Tranquility']\n",
      "EM: 0 \t F1: 0.33333333333333337 \t Recall: 1.0\n",
      "Question: when were the winnie the pooh books written\n",
      "Prediction: - Now We Are Six: 1927\n",
      "True Answers: ['1926', '1928']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: when does the new gotham season come out\n",
      "Prediction: The new Gotham season is scheduled to be released on March 8, 2018.\n",
      "True Answers: ['September 21 , 2017']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: how many students attend university of texas at austin\n",
      "Prediction: There were 51,331 students enrolled at the University of Texas at Austin in Fall 2016, with 40,168 undergraduate students and 11,163 postgraduate students.\n",
      "True Answers: ['over 50,000']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: who starred in the remake of true grit\n",
      "Prediction: Hailee Steinfeld starred as Mattie Ross and Jeff Bridges as Deputy U.S. Marshal Reuben J. \"Rooster\" Cogburn in the remake of True Grit. Other cast members include Matt Damon, Josh Brolin, and Barry Pepper.\n",
      "True Answers: ['Hailee Steinfeld', 'Jeff Bridges', 'Matt Damon', 'Josh Brolin', 'Barry Pepper']\n",
      "EM: 0 \t F1: 0.1142857142857143 \t Recall: 1.0\n",
      "Question: what year did the price is right first air\n",
      "Prediction: The Price is Right first aired on November 26, 1956.\n",
      "True Answers: ['1956']\n",
      "EM: 0 \t F1: 0.19999999999999998 \t Recall: 1.0\n",
      "Question: what is the longest panic at the disco song title\n",
      "Prediction: The longest Panic! at the Disco song title is \"Lying Is the Most Fun a Girl Can Have Without Taking Her Clothes Off.\"\n",
      "True Answers: ['Bohemian Rhapsody']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: which best describes timbuktu under the mali empire\n",
      "Prediction: Timbuktu under the Mali Empire is best described as a place of trade, entertainment, and education.\n",
      "True Answers: ['a place of trade , entertainment , and education']\n",
      "EM: 0 \t F1: 0.6 \t Recall: 1.0\n",
      "Question: which government had more power under the articles of confederation\n",
      "Prediction: Under the Articles of Confederation, state governments had more power than the federal government.\n",
      "True Answers: ['states']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: how many super bowl games has the patriots played in\n",
      "Prediction: The Patriots have played in 10 Super Bowl games.\n",
      "True Answers: ['ten']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: who played junior on in the heat of the night\n",
      "Prediction: Carlos Alan Autry Jr. played the role of Captain Bubba Skinner on the NBC television series, In the Heat of the Night.\n",
      "True Answers: ['Christian LeBlanc']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: which government had more power under the articles of confederation\n",
      "Prediction: Under the Articles of Confederation, state governments had more power than the federal government.\n",
      "True Answers: ['the states']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: who sings two pints of lager and a packet of crisps\n",
      "Prediction: Splodgenessabounds is the band that sings \"Two Pints of Lager and a Packet of Crisps.\"\n",
      "True Answers: ['Christian Henson']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: where does the donkey talk in the bible\n",
      "Prediction: The talking donkey appears in the Bible in Numbers 22:28.\n",
      "True Answers: ['Numbers 22 : 28']\n",
      "EM: 0 \t F1: 0.18181818181818182 \t Recall: 0.3333333333333333\n",
      "Question: when was the debating club established in almora\n",
      "Prediction: \n",
      "True Answers: ['1871 A.D.']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: when was the debating club established in almora\n",
      "Prediction: \n",
      "True Answers: ['1871']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: how many super bowl games has the patriots played in\n",
      "Prediction: The Patriots have played in 10 Super Bowl games.\n",
      "True Answers: ['ten times']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: when was the chain first used for f1\n",
      "Prediction: The chain first used for F1 in 1950 when the Formula One World Championship was officially established.\n",
      "True Answers: ['1978']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: where did the ashes from ash wednesday originate\n",
      "Prediction: Ash Wednesday ashes originated from the burning of palm leaves from the previous year's Palm Sunday celebrations.\n",
      "True Answers: ['Pope Gregory I the Great']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: what year is the deer hunter set in\n",
      "Prediction: The Deer Hunter is set in the year 1965.\n",
      "True Answers: ['late 1967']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: who sang the most number of songs in the world\n",
      "Prediction: \n",
      "True Answers: ['Asha Bhosle']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: how many super bowl games has the patriots played in\n",
      "Prediction: The Patriots have played in 10 Super Bowl games.\n",
      "True Answers: ['10']\n",
      "EM: 0 \t F1: 0.2222222222222222 \t Recall: 1.0\n",
      "Question: who did puerto rico belong to before the u.s\n",
      "Prediction: Puerto Rico belonged to Spain before the U.S.\n",
      "True Answers: ['indigenous Taíno people', 'Taíno']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: what year is the deer hunter set in\n",
      "Prediction: The Deer Hunter is set in the year 1965.\n",
      "True Answers: ['1967']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: nba record for most double doubles in a season\n",
      "Prediction: The NBA record for most double-doubles in a season is held by Wilt Chamberlain, who recorded 227 double-doubles during the 1960-61 season.\n",
      "True Answers: ['Tim Duncan leads the National Basketball Association ( NBA ) in the points - rebounds combination with 840', 'John Stockton leads the points - assists combination with 714']\n",
      "EM: 0 \t F1: 0.125 \t Recall: 0.15384615384615385\n",
      "Question: what is the origin of the name marilyn\n",
      "Prediction: The origin of the name Marilyn comes from blending the English given names Mary and Lynn. It started to be used in the 1920s and gained popularity in the 1930s, 1940s, and 1950s.\n",
      "True Answers: ['blend of the English given names Mary and Lynn']\n",
      "EM: 0 \t F1: 0.3888888888888889 \t Recall: 0.875\n",
      "Question: when is dragon ball super episode 131 releasing\n",
      "Prediction: Dragon Ball Super Episode 131 was released on March 25, 2018.\n",
      "True Answers: ['TBA']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: how many seasons of from dusk till dawn are there\n",
      "Prediction: There are 3 seasons of From Dusk Till Dawn: The Series.\n",
      "True Answers: ['third season']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: how many walker texas ranger seasons are there\n",
      "Prediction: There are 8 seasons of Walker, Texas Ranger.\n",
      "True Answers: ['Eight']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "=======================================\n",
      "Average EM: 0.005\n",
      "Average F1: 0.22873285469719287\n",
      "Average Recall: 0.7319256264504997\n"
     ]
    }
   ],
   "source": [
    "all_em_scores = []\n",
    "all_f1_scores = []\n",
    "all_recall_scores = []\n",
    "for i in range(len(retrieve_answers)):\n",
    "    prediction = retrieve_answers[i]\n",
    "    gold_answers = answers[i]\n",
    "\n",
    "    em_score = max((compute_exact_match(prediction, answer)) for answer in gold_answers)\n",
    "    f1_score = max((compute_f1_recall(prediction, answer)[0]) for answer in gold_answers)\n",
    "    recall_score = max((compute_f1_recall(prediction, answer)[1]) for answer in gold_answers)\n",
    "\n",
    "    all_em_scores.append(em_score)\n",
    "    all_f1_scores.append(f1_score)\n",
    "    all_recall_scores.append(recall_score)\n",
    "\n",
    "    if i % 10 == 0 or recall_score < 0.3:\n",
    "        print(f\"Question: {questions[i]}\")\n",
    "        print(f\"Prediction: {prediction}\")\n",
    "        print(f\"True Answers: {gold_answers}\")\n",
    "        print(f\"EM: {em_score} \\t F1: {f1_score} \\t Recall: {recall_score}\")\n",
    "\n",
    "print(\"=======================================\")\n",
    "print(f\"Average EM: {sum(all_em_scores) / len(all_em_scores)}\")\n",
    "print(f\"Average F1: {sum(all_f1_scores) / len(all_f1_scores)}\")\n",
    "print(f\"Average Recall: {sum(all_recall_scores) / len(all_recall_scores)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaml_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
