{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"pyautogen[retrievechat]~=0.1.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_MULTIHOP = \"\"\"You're a retrieve augmented chatbot. You answer user's questions based on your own knowledge and the context provided by the user. You must think step-by-step.\n",
    "First, please learn the following examples of context and question pairs and their corresponding answers.\n",
    "\n",
    "Context:\n",
    "Kurram Garhi: Kurram Garhi is a small village located near the city of Bannu, which is the part of Khyber Pakhtunkhwa province of Pakistan. Its population is approximately 35000.\n",
    "Trojkrsti: Trojkrsti is a village in Municipality of Prilep, Republic of Macedonia.\n",
    "Q: Are both Kurram Garhi and Trojkrsti located in the same country?\n",
    "A: Kurram Garhi is located in the country of Pakistan. Trojkrsti is located in the country of Republic of Macedonia. Thus, they are not in the same country. So the answer is: no.\n",
    "\n",
    "\n",
    "Context:\n",
    "Early Side of Later: Early Side of Later is the third studio album by English singer- songwriter Matt Goss. It was released on 21 June 2004 by Concept Music and reached No. 78 on the UK Albums Chart.\n",
    "What's Inside: What's Inside is the fourteenth studio album by British singer- songwriter Joan Armatrading.\n",
    "Q: Which album was released earlier, What'S Inside or Cassandra'S Dream (Album)?\n",
    "A: What's Inside was released in the year 1995. Cassandra's Dream (album) was released in the year 2008. Thus, of the two, the album to release earlier is What's Inside. So the answer is: What's Inside.\n",
    "\n",
    "\n",
    "Context:\n",
    "Maria Alexandrovna (Marie of Hesse): Maria Alexandrovna , born Princess Marie of Hesse and by Rhine (8 August 1824 – 3 June 1880) was Empress of Russia as the first wife of Emperor Alexander II.\n",
    "Grand Duke Alexei Alexandrovich of Russia: Grand Duke Alexei Alexandrovich of Russia,(Russian: Алексей Александрович; 14 January 1850 (2 January O.S.) in St. Petersburg – 14 November 1908 in Paris) was the fifth child and the fourth son of Alexander II of Russia and his first wife Maria Alexandrovna (Marie of Hesse).\n",
    "Q: What is the cause of death of Grand Duke Alexei Alexandrovich Of Russia's mother?\n",
    "A: The mother of Grand Duke Alexei Alexandrovich of Russia is Maria Alexandrovna. Maria Alexandrovna died from tuberculosis. So the answer is: tuberculosis.\n",
    "\n",
    "\n",
    "Context:\n",
    "Laughter in Hell: Laughter in Hell is a 1933 American Pre-Code drama film directed by Edward L. Cahn and starring Pat O'Brien. The film's title was typical of the sensationalistic titles of many Pre-Code films.\n",
    "Edward L. Cahn: Edward L. Cahn (February 12, 1899 – August 25, 1963) was an American film director.\n",
    "Q: When did the director of film Laughter In Hell die?\n",
    "A: The film Laughter In Hell was directed by Edward L. Cahn. Edward L. Cahn died on August 25, 1963. So the answer is: August 25, 1963.\n",
    "\n",
    "Second, please complete the answer by thinking step-by-step.\n",
    "\n",
    "Context:\n",
    "{input_context}\n",
    "Q: {input_question}\n",
    "A:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/FLAML/docs/reference/autogen/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models to use:  ['gpt-3.5-turbo']\n"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\".config.local\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"gpt-4\",\n",
    "            \"gpt4\",\n",
    "            \"gpt-4-32k\",\n",
    "            \"gpt-4-32k-0314\",\n",
    "            \"gpt-35-turbo\",\n",
    "            \"gpt-3.5-turbo\",\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "assert len(config_list) > 0\n",
    "config_list[0]['model'] = 'gpt-3.5-turbo'\n",
    "print(\"models to use: \", [config_list[i][\"model\"] for i in range(len(config_list))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct agents for RetrieveChat\n",
    "\n",
    "We start by initialzing the `RetrieveAssistantAgent` and `RetrieveUserProxyAgent`. The system message needs to be set to \"You are a helpful assistant.\" for RetrieveAssistantAgent. The detailed instructions are given in the user message. Later we will use the `RetrieveUserProxyAgent.generate_init_prompt` to combine the instructions and a math problem for an initial prompt to be sent to the LLM assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "import chromadb\n",
    "\n",
    "# 1. create an RetrieveAssistantAgent instance named \"assistant\"\n",
    "assistant = RetrieveAssistantAgent(\n",
    "    name=\"assistant\", \n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    max_consecutive_auto_reply=6,\n",
    "    llm_config={\n",
    "        \"request_timeout\": 600,\n",
    "        \"seed\": 43,\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    ")\n",
    "\n",
    "# 2. create the RetrieveUserProxyAgent instance named \"ragproxyagent\"\n",
    "corpus_file = \"https://huggingface.co/datasets/thinkall/2WikiMultihopQA/resolve/main/corpus.txt\"\n",
    "\n",
    "# Create a new collection for NaturalQuestions dataset\n",
    "ragproxyagent = RetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=5,\n",
    "    retrieve_config={\n",
    "        \"task\": \"multihop\",\n",
    "        \"docs_path\": corpus_file,\n",
    "        \"chunk_token_size\": 2000,\n",
    "        \"model\": config_list[0][\"model\"],\n",
    "        \"client\": chromadb.PersistentClient(path=\"/tmp/chromadb\"),\n",
    "        \"collection_name\": \"2wikimultihopqa\",\n",
    "        \"chunk_mode\": \"one_line\",\n",
    "        \"embedding_model\": \"all-MiniLM-L6-v2\",\n",
    "        \"customized_prompt\": PROMPT_MULTIHOP,\n",
    "        \"customized_answer_prefix\": \"the answer is\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2WikiMultihopQA\n",
    "\n",
    "Use RetrieveChat to answer questions for [2WikiMultihopQA](https://github.com/Alab-NII/2wikimultihop) dataset.\n",
    "\n",
    "We'll first create a new document collection based on all the context corpus, then we select some questions and answer them with RetrieveChat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-09-22 22:48:47--  https://huggingface.co/datasets/thinkall/2WikiMultihopQA/resolve/main/queries.jsonl\n",
      "Resolving huggingface.co (huggingface.co)... 13.32.50.80, 13.32.50.102, 13.32.50.129, ...\n",
      "Connecting to huggingface.co (huggingface.co)|13.32.50.80|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2137700 (2.0M) [text/plain]\n",
      "Saving to: ‘/tmp/chromadb/queries.jsonl’\n",
      "\n",
      "/tmp/chromadb/queri 100%[===================>]   2.04M  1.73MB/s    in 1.2s    \n",
      "\n",
      "2023-09-22 22:48:48 (1.73 MB/s) - ‘/tmp/chromadb/queries.jsonl’ saved [2137700/2137700]\n",
      "\n",
      "['Who is the mother of the director of film Polish-Russian War (Film)?', 'Which film came out first, Blind Shaft or The Mask Of Fu Manchu?', \"When did John V, Prince Of Anhalt-Zerbst's father die?\", 'What is the award that the director of film Wearing Velvet Slippers Under A Golden Umbrella won?', 'Where was the director of film Ronnie Rocket born?']\n",
      "[['Małgorzata Braunek'], ['The Mask Of Fu Manchu'], ['12 June 1516'], ['Myanmar Motion Picture Academy Awards'], ['Missoula, Montana']]\n",
      "Number of questions: 12576\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "queries_file = \"https://huggingface.co/datasets/thinkall/2WikiMultihopQA/resolve/main/queries.jsonl\"\n",
    "!wget -O /tmp/chromadb/queries.jsonl $queries_file\n",
    "queries = [json.loads(line) for line in open(\"/tmp/chromadb/queries.jsonl\").readlines() if line]\n",
    "questions = [q[\"text\"] for q in queries]\n",
    "answers = [q[\"metadata\"][\"answer\"] for q in queries]\n",
    "print(questions[:5])\n",
    "print(answers[:5])\n",
    "print(\"Number of questions:\", len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import sys\n",
    "\n",
    "class Capturing(list):\n",
    "    def __enter__(self):\n",
    "        self._stdout = sys.stdout\n",
    "        sys.stdout = self._stringio = StringIO()\n",
    "        return self\n",
    "    def __exit__(self, *args):\n",
    "        self.extend(self._stringio.getvalue().splitlines())\n",
    "        del self._stringio    # free up some memory\n",
    "        sys.stdout = self._stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress 0.00%, Time Used 0.00 hours\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lijiang1/anaconda3/envs/autogen/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Collection 2wikimultihopqa already exists.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "\n",
    "num_questions = 20\n",
    "n_results = 15  # number of documents to retrieve\n",
    "\n",
    "retrieve_answers = []\n",
    "questions_sample = []\n",
    "answers_sample = []\n",
    "st = time.time()\n",
    "for idx, qa_problem in enumerate(questions[:num_questions]):\n",
    "    if idx % 100 == 0:\n",
    "        ct = time.time()\n",
    "        print(f\"\\nProgress {idx/num_questions*100:.2f}%, Time Used {(ct-st)/3600:.2f} hours\\n\")\n",
    "    assistant.reset()\n",
    "    try:\n",
    "        with Capturing() as print_output:\n",
    "            ragproxyagent.initiate_chat(assistant, problem=qa_problem, n_results=n_results)\n",
    "        match = re.search(r\"the answer is(.+)\", print_output[-3].split(\"\\n\")[-1], re.IGNORECASE)\n",
    "        if match:\n",
    "            punctuation_pattern = r'[!\\\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]'\n",
    "            retrieve_answers.append(re.sub(punctuation_pattern, '', match.group(1)))\n",
    "        else:\n",
    "            retrieve_answers.append(\"\")\n",
    "        questions_sample.append(qa_problem)\n",
    "        answers_sample.append(answers[:num_questions][idx])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Error in problem: \", qa_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ': The Mask of Fu Manchu.', '', '', '']\n",
      "len(retrieve_answers): 20\n",
      "len(answers_sample): 20\n",
      "len(questions_sample): 20\n"
     ]
    }
   ],
   "source": [
    "print(retrieve_answers[:5])\n",
    "print(\"len(retrieve_answers):\", len(retrieve_answers))\n",
    "print(\"len(answers_sample):\", len(answers_sample))\n",
    "print(\"len(questions_sample):\", len(questions_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://qa.fastforwardlabs.com/no%20answer/null%20threshold/bert/distilbert/exact%20match/f1/robust%20predictions/2020/06/09/Evaluating_BERT_on_SQuAD.html#F1\n",
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    import string, re\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1_recall(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "    \n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens), int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    \n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0, 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec), rec\n",
    "\n",
    "def get_gold_answers(example):\n",
    "    \"\"\"helper function that retrieves all possible true answers from a squad2.0 example\"\"\"\n",
    "    \n",
    "    gold_answers = [answer[\"text\"] for answer in example.answers if answer[\"text\"]]\n",
    "\n",
    "    # if gold_answers doesn't exist it's because this is a negative example - \n",
    "    # the only correct answer is an empty string\n",
    "    if not gold_answers:\n",
    "        gold_answers = [\"\"]\n",
    "        \n",
    "    return gold_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the mother of the director of film Polish-Russian War (Film)?\n",
      "Prediction: \n",
      "True Answers: ['Małgorzata Braunek']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: Which film came out first, Blind Shaft or The Mask Of Fu Manchu?\n",
      "Prediction: : The Mask of Fu Manchu.\n",
      "True Answers: ['The Mask Of Fu Manchu']\n",
      "EM: 1 \t F1: 1.0 \t Recall: 1.0\n",
      "Question: When did John V, Prince Of Anhalt-Zerbst's father die?\n",
      "Prediction: \n",
      "True Answers: ['12 June 1516']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: What is the award that the director of film Wearing Velvet Slippers Under A Golden Umbrella won?\n",
      "Prediction: \n",
      "True Answers: ['Myanmar Motion Picture Academy Awards']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: Where was the director of film Ronnie Rocket born?\n",
      "Prediction: \n",
      "True Answers: ['Missoula, Montana']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: Who is Charles Bretagne Marie De La Trémoille's paternal grandfather?\n",
      "Prediction: \n",
      "True Answers: ['Charles Armand René de La Trémoille']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: Where was the father of Ștefan I. Nenițescu born?\n",
      "Prediction: : Galați, Romania.\n",
      "True Answers: ['Galați']\n",
      "EM: 0 \t F1: 0.6666666666666666 \t Recall: 1.0\n",
      "Question: Are North Marion High School (Oregon) and Seoul High School both located in the same country?\n",
      "Prediction: : no.\n",
      "True Answers: ['no']\n",
      "EM: 1 \t F1: 1.0 \t Recall: 1.0\n",
      "Question: Which film has the director who was born later, El Extraño Viaje or Love In Pawn?\n",
      "Prediction: : it cannot be determined.\n",
      "True Answers: ['El Extraño Viaje']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: Who is the maternal grandfather of Antiochus X Eusebes?\n",
      "Prediction: \n",
      "True Answers: ['Ptolemy IX Lathyros']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: Which film has the director died first, Crimen A Las Tres or The Working Class Goes To Heaven?\n",
      "Prediction: : The Working Class Goes To Heaven.\n",
      "True Answers: ['The Working Class Goes To Heaven']\n",
      "EM: 1 \t F1: 1.0 \t Recall: 1.0\n",
      "Question: Which film has the director born first, Once A Gentleman or The Girl In White?\n",
      "Prediction: : Once A Gentleman.\n",
      "True Answers: ['Once A Gentleman']\n",
      "EM: 1 \t F1: 1.0 \t Recall: 1.0\n",
      "Question: Which film has the director who died earlier, Il Seduttore or The Trial Of Joan Of Arc?\n",
      "Prediction: : The Trial of Joan of Arc.\n",
      "True Answers: ['The Trial Of Joan Of Arc']\n",
      "EM: 1 \t F1: 0.8000000000000002 \t Recall: 0.8\n",
      "Question: Where was the director of film Thomas Jefferson (Film) born?\n",
      "Prediction:  unknown.\n",
      "True Answers: ['Brooklyn']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: Why did Grand Duke Kirill Vladimirovich Of Russia's wife die?\n",
      "Prediction: \n",
      "True Answers: ['stroke']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: Where was the place of death of the director of film Beat Girl?\n",
      "Prediction: \n",
      "True Answers: ['Nice']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: Who died first, Fleetwood Sheppard or George William Whitaker?\n",
      "Prediction: : Fleetwood Sheppard.\n",
      "True Answers: ['Fleetwood Sheppard']\n",
      "EM: 1 \t F1: 1.0 \t Recall: 1.0\n",
      "Question: Which film has the director born first, The Raven'S Dance or Keïta! L'Héritage Du Griot?\n",
      "Prediction:  The Raven's Dance.\n",
      "True Answers: [\"The Raven'S Dance\"]\n",
      "EM: 1 \t F1: 1.0 \t Recall: 1.0\n",
      "Question: When did Jean Martin (Singer)'s husband die?\n",
      "Prediction: : March 7, 1983.\n",
      "True Answers: ['1983']\n",
      "EM: 0 \t F1: 0.5 \t Recall: 1.0\n",
      "Question: Which film has the director who died earlier, Tangled Destinies or The Daltons' Women?\n",
      "Prediction: : Tangled Destinies.\n",
      "True Answers: ['Tangled Destinies']\n",
      "EM: 1 \t F1: 1.0 \t Recall: 1.0\n",
      "=======================================\n",
      "Average EM: 0.4\n",
      "Average F1: 0.44833333333333325\n",
      "Average Recall: 0.49000000000000005\n"
     ]
    }
   ],
   "source": [
    "all_em_scores = []\n",
    "all_f1_scores = []\n",
    "all_recall_scores = []\n",
    "for i in range(len(retrieve_answers)):\n",
    "    prediction = retrieve_answers[i]\n",
    "    gold_answers = answers_sample[i]\n",
    "\n",
    "    em_score = max((compute_exact_match(prediction, answer)) for answer in gold_answers)\n",
    "    f1_score = max((compute_f1_recall(prediction, answer)[0]) for answer in gold_answers)\n",
    "    recall_score = max((compute_f1_recall(prediction, answer)[1]) for answer in gold_answers)\n",
    "\n",
    "    all_em_scores.append(em_score)\n",
    "    all_f1_scores.append(f1_score)\n",
    "    all_recall_scores.append(recall_score)\n",
    "\n",
    "    # if i % 10 == 0 or recall_score < 0.3:\n",
    "    print(f\"Question: {questions_sample[i]}\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    print(f\"True Answers: {gold_answers}\")\n",
    "    print(f\"EM: {em_score} \\t F1: {f1_score} \\t Recall: {recall_score}\")\n",
    "\n",
    "print(\"=======================================\")\n",
    "print(f\"Average EM: {sum(all_em_scores) / len(all_em_scores)}\")\n",
    "print(f\"Average F1: {sum(all_f1_scores) / len(all_f1_scores)}\")\n",
    "print(f\"Average Recall: {sum(all_recall_scores) / len(all_recall_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| num_questions | n_results (number of documents) | Average EM | Average F1 | Average Recall |\n",
    "|---------------|---------------------------------|------------|------------|----------------|\n",
    "| 20            | 15                              | 0.4210     | 0.4719     | 0.5158         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for qa_problem in questions[:min(20, num_questions)]:\n",
    "    print(f\"\\n\\n>>>>>>>>>>>>>> case: {qa_problem} <<<<<<<<<<<<<<\\n\\n\")\n",
    "    assistant.reset()\n",
    "    try:\n",
    "        ragproxyagent.initiate_chat(assistant, problem=qa_problem, n_results=n_results)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaml_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
