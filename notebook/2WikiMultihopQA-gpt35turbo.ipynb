{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install flaml[retrievechat]~=2.0.0rc5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/FLAML/docs/reference/autogen/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"ALL_PROXY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models to use:  ['gpt-3.5-turbo']\n"
     ]
    }
   ],
   "source": [
    "from flaml import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    env_or_file=\".config.local\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"gpt-4\",\n",
    "            \"gpt4\",\n",
    "            \"gpt-4-32k\",\n",
    "            \"gpt-4-32k-0314\",\n",
    "            \"gpt-35-turbo\",\n",
    "            \"gpt-3.5-turbo\",\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "assert len(config_list) > 0\n",
    "config_list[0]['model'] = 'gpt-3.5-turbo'\n",
    "print(\"models to use: \", [config_list[i][\"model\"] for i in range(len(config_list))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct agents for RetrieveChat\n",
    "\n",
    "We start by initialzing the `RetrieveAssistantAgent` and `RetrieveUserProxyAgent`. The system message needs to be set to \"You are a helpful assistant.\" for RetrieveAssistantAgent. The detailed instructions are given in the user message. Later we will use the `RetrieveUserProxyAgent.generate_init_prompt` to combine the instructions and a math problem for an initial prompt to be sent to the LLM assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml.autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from flaml.autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "import chromadb\n",
    "\n",
    "# 1. create an RetrieveAssistantAgent instance named \"assistant\"\n",
    "assistant = RetrieveAssistantAgent(\n",
    "    name=\"assistant\", \n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    max_consecutive_auto_reply=5,\n",
    "    llm_config={\n",
    "        \"request_timeout\": 600,\n",
    "        \"seed\": 43,\n",
    "        \"config_list\": config_list,\n",
    "    },\n",
    ")\n",
    "\n",
    "# 2. create the RetrieveUserProxyAgent instance named \"ragproxyagent\"\n",
    "corpus_file = \"https://huggingface.co/datasets/thinkall/2WikiMultihopQA/resolve/main/corpus.txt\"\n",
    "\n",
    "# Create a new collection for NaturalQuestions dataset\n",
    "ragproxyagent = RetrieveUserProxyAgent(\n",
    "    name=\"ragproxyagent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=5,\n",
    "    retrieve_config={\n",
    "        \"task\": \"multihop\",\n",
    "        \"docs_path\": corpus_file,\n",
    "        \"chunk_token_size\": 2000,\n",
    "        \"model\": config_list[0][\"model\"],\n",
    "        \"client\": chromadb.PersistentClient(path=\"/tmp/chromadb\"),\n",
    "        \"collection_name\": \"2wikimultihopqa\",\n",
    "        \"chunk_mode\": \"one_line\",\n",
    "        \"embedding_model\": \"all-MiniLM-L6-v2\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2WikiMultihopQA\n",
    "\n",
    "Use RetrieveChat to answer questions for [2WikiMultihopQA](https://github.com/Alab-NII/2wikimultihop) dataset.\n",
    "\n",
    "We'll first create a new document collection based on all the context corpus, then we select some questions and answer them with RetrieveChat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-09-07 17:50:38--  https://huggingface.co/datasets/thinkall/2WikiMultihopQA/resolve/main/queries.jsonl\n",
      "Resolving huggingface.co (huggingface.co)... 18.154.227.7, 18.154.227.69, 18.154.227.67, ...\n",
      "Connecting to huggingface.co (huggingface.co)|18.154.227.7|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2137700 (2.0M) [text/plain]\n",
      "Saving to: ‘/tmp/chromadb/queries.jsonl’\n",
      "\n",
      "/tmp/chromadb/queri 100%[===================>]   2.04M  10.4MB/s    in 0.2s    \n",
      "\n",
      "2023-09-07 17:50:38 (10.4 MB/s) - ‘/tmp/chromadb/queries.jsonl’ saved [2137700/2137700]\n",
      "\n",
      "['Who is the mother of the director of film Polish-Russian War (Film)?', 'Which film came out first, Blind Shaft or The Mask Of Fu Manchu?', \"When did John V, Prince Of Anhalt-Zerbst's father die?\", 'What is the award that the director of film Wearing Velvet Slippers Under A Golden Umbrella won?', 'Where was the director of film Ronnie Rocket born?']\n",
      "[['Małgorzata Braunek'], ['The Mask Of Fu Manchu'], ['12 June 1516'], ['Myanmar Motion Picture Academy Awards'], ['Missoula, Montana']]\n",
      "Number of questions: 12576\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "queries_file = \"https://huggingface.co/datasets/thinkall/2WikiMultihopQA/resolve/main/queries.jsonl\"\n",
    "!wget -O /tmp/chromadb/queries.jsonl $queries_file\n",
    "queries = [json.loads(line) for line in open(\"/tmp/chromadb/queries.jsonl\").readlines() if line]\n",
    "questions = [q[\"text\"] for q in queries]\n",
    "answers = [q[\"metadata\"][\"answer\"] for q in queries]\n",
    "print(questions[:5])\n",
    "print(answers[:5])\n",
    "print(\"Number of questions:\", len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO \n",
    "import sys\n",
    "\n",
    "class Capturing(list):\n",
    "    def __enter__(self):\n",
    "        self._stdout = sys.stdout\n",
    "        sys.stdout = self._stringio = StringIO()\n",
    "        return self\n",
    "    def __exit__(self, *args):\n",
    "        self.extend(self._stringio.getvalue().splitlines())\n",
    "        del self._stringio    # free up some memory\n",
    "        sys.stdout = self._stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress 0.00%, Time Used 0.00 hours\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collection 2wikimultihopqa already exists.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "\n",
    "num_questions = 20\n",
    "n_results = 5  # number of documents to retrieve\n",
    "\n",
    "retrieve_answers = []\n",
    "questions_sample = []\n",
    "answers_sample = []\n",
    "st = time.time()\n",
    "for idx, qa_problem in enumerate(questions[:num_questions]):\n",
    "    if idx % 100 == 0:\n",
    "        ct = time.time()\n",
    "        print(f\"\\nProgress {idx/num_questions*100:.2f}%, Time Used {(ct-st)/3600:.2f} hours\\n\")\n",
    "    assistant.reset()\n",
    "    try:\n",
    "        with Capturing() as print_output:\n",
    "            ragproxyagent.initiate_chat(assistant, problem=qa_problem, n_results=n_results)\n",
    "        retrieve_answers.append(re.sub(r'answer is', '', print_output[-3].split(\"\\n\")[-1], flags=re.IGNORECASE))\n",
    "        questions_sample.append(qa_problem)\n",
    "        answers_sample.append(answers[:num_questions][idx])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Error in problem: \", qa_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Xawery Żuławski.', ' `Update Context Which film came out first, Blind Shaft or The Mask Of Fu Manchu?`.', 'Answer: Update Context When did Ernest I, Prince of Anhalt-Dessau die?', ': Update Context: What is the award that the director of the film \"Wearing Velvet Slippers Under A Golden Umbrella\" won?', ': Update Context: Who is the director of the film \"Ronnie Rocket\"?']\n",
      "len(retrieve_answers): 20\n",
      "len(answers_sample): 20\n",
      "len(questions_sample): 20\n"
     ]
    }
   ],
   "source": [
    "print(retrieve_answers[:5])\n",
    "print(\"len(retrieve_answers):\", len(retrieve_answers))\n",
    "print(\"len(answers_sample):\", len(answers_sample))\n",
    "print(\"len(questions_sample):\", len(questions_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://qa.fastforwardlabs.com/no%20answer/null%20threshold/bert/distilbert/exact%20match/f1/robust%20predictions/2020/06/09/Evaluating_BERT_on_SQuAD.html#F1\n",
    "def normalize_text(s):\n",
    "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
    "    import string, re\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact_match(prediction, truth):\n",
    "    return int(normalize_text(prediction) == normalize_text(truth))\n",
    "\n",
    "def compute_f1_recall(prediction, truth):\n",
    "    pred_tokens = normalize_text(prediction).split()\n",
    "    truth_tokens = normalize_text(truth).split()\n",
    "    \n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens), int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    \n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0, 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec), rec\n",
    "\n",
    "def get_gold_answers(example):\n",
    "    \"\"\"helper function that retrieves all possible true answers from a squad2.0 example\"\"\"\n",
    "    \n",
    "    gold_answers = [answer[\"text\"] for answer in example.answers if answer[\"text\"]]\n",
    "\n",
    "    # if gold_answers doesn't exist it's because this is a negative example - \n",
    "    # the only correct answer is an empty string\n",
    "    if not gold_answers:\n",
    "        gold_answers = [\"\"]\n",
    "        \n",
    "    return gold_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the mother of the director of film Polish-Russian War (Film)?\n",
      "Prediction:  Xawery Żuławski.\n",
      "True Answers: ['Małgorzata Braunek']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: Which film came out first, Blind Shaft or The Mask Of Fu Manchu?\n",
      "Prediction:  `Update Context Which film came out first, Blind Shaft or The Mask Of Fu Manchu?`.\n",
      "True Answers: ['The Mask Of Fu Manchu']\n",
      "EM: 0 \t F1: 0.4444444444444445 \t Recall: 1.0\n",
      "Question: When did John V, Prince Of Anhalt-Zerbst's father die?\n",
      "Prediction: Answer: Update Context When did Ernest I, Prince of Anhalt-Dessau die?\n",
      "True Answers: ['12 June 1516']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: What is the award that the director of film Wearing Velvet Slippers Under A Golden Umbrella won?\n",
      "Prediction: : Update Context: What is the award that the director of the film \"Wearing Velvet Slippers Under A Golden Umbrella\" won?\n",
      "True Answers: ['Myanmar Motion Picture Academy Awards']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: Where was the director of film Ronnie Rocket born?\n",
      "Prediction: : Update Context: Who is the director of the film \"Ronnie Rocket\"?\n",
      "True Answers: ['Missoula, Montana']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: Who is Charles Bretagne Marie De La Trémoille's paternal grandfather?\n",
      "Prediction:  Charles Armand René de La Trémoille.\n",
      "True Answers: ['Charles Armand René de La Trémoille']\n",
      "EM: 1 \t F1: 1.0 \t Recall: 1.0\n",
      "Question: Where was the father of Ștefan I. Nenițescu born?\n",
      "Prediction: : Ioan S. Nenițescu was born in Galați, Romania.\n",
      "True Answers: ['Galați']\n",
      "EM: 0 \t F1: 0.2222222222222222 \t Recall: 1.0\n",
      "Question: Are North Marion High School (Oregon) and Seoul High School both located in the same country?\n",
      "Prediction:  No, North Marion High School (Oregon) and Seoul High School are not located in the same country.\n",
      "True Answers: ['no']\n",
      "EM: 0 \t F1: 0.11764705882352941 \t Recall: 1.0\n",
      "Question: Which film has the director who was born later, El Extraño Viaje or Love In Pawn?\n",
      "Prediction:  Update Context: Which film has the director who was born later, El Extraño Viaje or Love In Pawn?\n",
      "True Answers: ['El Extraño Viaje']\n",
      "EM: 0 \t F1: 0.3 \t Recall: 1.0\n",
      "Question: Who is the maternal grandfather of Antiochus X Eusebes?\n",
      "Prediction: : The maternal grandfather of Antiochus X Eusebes is unknown based on the given context.\n",
      "True Answers: ['Ptolemy IX Lathyros']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: Which film has the director died first, Crimen A Las Tres or The Working Class Goes To Heaven?\n",
      "Prediction: Answer: Update Context: Which film has the director died first, Crimen A Las Tres or The Working Class Goes To Heaven?\n",
      "True Answers: ['The Working Class Goes To Heaven']\n",
      "EM: 0 \t F1: 0.4347826086956522 \t Recall: 1.0\n",
      "Question: Which film has the director born first, Once A Gentleman or The Girl In White?\n",
      "Prediction: : Update Context What is the birthdate of the director of the film Once A Gentleman or The Girl In White?\n",
      "True Answers: ['Once A Gentleman']\n",
      "EM: 0 \t F1: 0.23529411764705882 \t Recall: 1.0\n",
      "Question: Which film has the director who died earlier, Il Seduttore or The Trial Of Joan Of Arc?\n",
      "Prediction: We don't have the information to answer the original question.\n",
      "True Answers: ['The Trial Of Joan Of Arc']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: Where was the director of film Thomas Jefferson (Film) born?\n",
      "Prediction: Step 3. Since we don't have the information about Ken Burns' birthplace, we can't answer the original question. We can rephrase the question with the extracted information, \"What is the birthplace of Ken Burns, the director of the film 'Thomas Jefferson'?\"\n",
      "True Answers: ['Brooklyn']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: Why did Grand Duke Kirill Vladimirovich Of Russia's wife die?\n",
      "Prediction: : Grand Duchess Kira Kirillovna of Russia died on September 8, 1967.\n",
      "True Answers: ['stroke']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: Where was the place of death of the director of film Beat Girl?\n",
      "Prediction: \n",
      "True Answers: ['Nice']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: Who died first, Fleetwood Sheppard or George William Whitaker?\n",
      "Prediction: : \"Fleetwood Sheppard died on August 25, 1698. No information is available about George William Whitaker's death.\"\n",
      "True Answers: ['Fleetwood Sheppard']\n",
      "EM: 0 \t F1: 0.2222222222222222 \t Recall: 1.0\n",
      "Question: Which film has the director born first, The Raven'S Dance or Keïta! L'Héritage Du Griot?\n",
      "Prediction: Answer: The director of The Raven's Dance, Markku Lehmuskallio, was born first.\n",
      "True Answers: [\"The Raven'S Dance\"]\n",
      "EM: 0 \t F1: 0.33333333333333337 \t Recall: 1.0\n",
      "Question: When did Jean Martin (Singer)'s husband die?\n",
      "Prediction: : Update Context When did William Black, the husband of Jean Martin (Singer), die?\n",
      "True Answers: ['1983']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "Question: Which film has the director who died earlier, Tangled Destinies or The Daltons' Women?\n",
      "Prediction: Since there is no information in the context about the death of any director, I cannot answer the original question. \n",
      "True Answers: ['Tangled Destinies']\n",
      "EM: 0 \t F1: 0 \t Recall: 0\n",
      "=======================================\n",
      "Average EM: 0.05\n",
      "Average F1: 0.16549730036942314\n",
      "Average Recall: 0.45\n"
     ]
    }
   ],
   "source": [
    "all_em_scores = []\n",
    "all_f1_scores = []\n",
    "all_recall_scores = []\n",
    "for i in range(len(retrieve_answers)):\n",
    "    prediction = retrieve_answers[i]\n",
    "    gold_answers = answers_sample[i]\n",
    "\n",
    "    em_score = max((compute_exact_match(prediction, answer)) for answer in gold_answers)\n",
    "    f1_score = max((compute_f1_recall(prediction, answer)[0]) for answer in gold_answers)\n",
    "    recall_score = max((compute_f1_recall(prediction, answer)[1]) for answer in gold_answers)\n",
    "\n",
    "    all_em_scores.append(em_score)\n",
    "    all_f1_scores.append(f1_score)\n",
    "    all_recall_scores.append(recall_score)\n",
    "\n",
    "    # if i % 10 == 0 or recall_score < 0.3:\n",
    "    print(f\"Question: {questions_sample[i]}\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    print(f\"True Answers: {gold_answers}\")\n",
    "    print(f\"EM: {em_score} \\t F1: {f1_score} \\t Recall: {recall_score}\")\n",
    "\n",
    "print(\"=======================================\")\n",
    "print(f\"Average EM: {sum(all_em_scores) / len(all_em_scores)}\")\n",
    "print(f\"Average F1: {sum(all_f1_scores) / len(all_f1_scores)}\")\n",
    "print(f\"Average Recall: {sum(all_recall_scores) / len(all_recall_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_questions = 20 \n",
    "\n",
    "## rephrase 1\n",
    "n_results = 5  # number of documents to retrieve   \n",
    "max_auto_reply = 3   \n",
    "\n",
    "Average EM: 0.05   \n",
    "Average F1: 0.1117725752508361   \n",
    "Average Recall: 0.25   \n",
    "\n",
    "## rephrase 2\n",
    "n_results = 5  # number of documents to retrieve   \n",
    "max_auto_reply = 3   \n",
    "\n",
    "Average EM: 0.1   \n",
    "Average F1: 0.18219201723905004   \n",
    "Average Recall: 0.4025   \n",
    "\n",
    "------\n",
    "n_results = 10   \n",
    "max_auto_reply = 3   \n",
    "\n",
    "Average EM: 0.1   \n",
    "Average F1: 0.1766518569150148   \n",
    "Average Recall: 0.27   \n",
    "\n",
    "----\n",
    "seed=43   \n",
    "max_auto_reply=5   \n",
    "n_results = 5  # number of documents to retrieve   \n",
    "\n",
    "Average EM: 0.1   \n",
    "Average F1: 0.20555407011289364    \n",
    "Average Recall: 0.42000000000000004   \n",
    "\n",
    "\n",
    "## rephrase 3\n",
    "n_results = 5  # number of documents to retrieve   \n",
    "max_auto_reply = 3   \n",
    "\n",
    "Average EM: 0.1   \n",
    "Average F1: 0.15410256410256412   \n",
    "Average Recall: 0.17333333333333334   \n",
    "\n",
    "\n",
    "## rephrase 4: rephrase 2 + 2 examples from original 1\n",
    "Average EM: 0.05    \n",
    "Average F1: 0.21064342520224874   \n",
    "Average Recall: 0.36666666666666664   \n",
    "\n",
    "## rephrase 5\n",
    "seed=43   \n",
    "max_auto_reply=5    \n",
    "n_results = 5  # number of documents to retriev   \n",
    "\n",
    "Average EM: 0.05   \n",
    "Average F1: 0.2185504201680672   \n",
    "Average Recall: 0.42333333333333323   \n",
    "\n",
    "## rephrase 7\n",
    "0.39   \n",
    "\n",
    "## rephrase 8\n",
    "seed=43   \n",
    "n_results = 5    \n",
    "max_auto_reply = 5   \n",
    "\n",
    "Average EM: 0.05   \n",
    "Average F1: 0.16549730036942314   \n",
    "Average Recall: 0.45   \n",
    "\n",
    "\n",
    "## original 1\n",
    "n_results = 5   \n",
    "max_auto_reply = 3   \n",
    "\n",
    "Average EM: 0.15   \n",
    "Average F1: 0.2505793226381462   \n",
    "Average Recall: 0.3333333333333333   \n",
    "\n",
    "## original 2\n",
    "n_results = 5    \n",
    "max_auto_reply = 3   \n",
    "\n",
    "Average EM: 0.0   \n",
    "Average F1: 0.12080128205128204   \n",
    "Average Recall: 0.2333333333333333   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for qa_problem in questions[:min(500, num_questions)]:\n",
    "#     print(f\"\\n\\n>>>>>>>>>>>>>> case: {qa_problem} <<<<<<<<<<<<<<\\n\\n\")\n",
    "#     assistant.reset()\n",
    "#     try:\n",
    "#         ragproxyagent.initiate_chat(assistant, problem=qa_problem, n_results=n_results)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Exception: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaml_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
