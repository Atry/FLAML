{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/FLAML/blob/main/notebook/research/autogen_agent_hanoi2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "FLAML offers an experimental feature of interactive LLM agents, which can be used to solve various tasks with human or automatic feedback, including tasks that require using tools via code.\n",
    "\n",
    "`AssistantAgent` is an LLM-based agent that can write Python code (in a Python coding block) for a user to execute for a given task. `UserProxyAgent` is an agent which serves as a proxy for a user to execute the code written by `AssistantAgent`. By setting `human_input_mode` properly, the `UserProxyAgent` can also prompt the user for feedback to `AssistantAgent`. For example, when `human_input_mode` is set to \"ALWAYS\", the `UserProxyAgent` will always prompt the user for feedback. When user feedback is provided, the `UserProxyAgent` will directly pass the feedback to `AssistantAgent` without doing any additional steps. When no user feedback is provided, the `UserProxyAgent` will execute the code written by `AssistantAgent` directly and return the execution results (success or failure and corresponding outputs) to `AssistantAgent`.\n",
    "\n",
    "\n",
    "## Requirements\n",
    "\n",
    "FLAML requires `Python>=3.8`. To run this notebook example, please install flaml with the [autogen] option:\n",
    "```bash\n",
    "pip install flaml[autogen]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T23:40:52.317406Z",
     "iopub.status.busy": "2023-02-13T23:40:52.316561Z",
     "iopub.status.idle": "2023-02-13T23:40:52.321193Z",
     "shell.execute_reply": "2023-02-13T23:40:52.320628Z"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install flaml[autogen]==2.0.0rc3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_openai_aoai`](https://microsoft.github.io/FLAML/docs/reference/autogen/oai/openai_utils#config_list_openai_aoai) function tries to create a list of configurations using Azure OpenAI endpoints and OpenAI endpoints. It assumes the api keys and api bases are stored in the corresponding environment variables or local txt files:\n",
    "\n",
    "- OpenAI API key: os.environ[\"OPENAI_API_KEY\"] or `openai_api_key_file=\"key_openai.txt\"`.\n",
    "- Azure OpenAI API key: os.environ[\"AZURE_OPENAI_API_KEY\"] or `aoai_api_key_file=\"key_aoai.txt\"`. Multiple keys can be stored, one per line.\n",
    "- Azure OpenAI API base: os.environ[\"AZURE_OPENAI_API_BASE\"] or `aoai_api_base_file=\"base_aoai.txt\"`. Multiple bases can be stored, one per line.\n",
    "\n",
    "It's OK to have only the OpenAI API key, or only the Azure OpenAI API key + base.\n",
    "The following code looks for key files in key_file_path. Change it into the relevant path. If you open this notebook in google colab, you can upload your files by click the file icon on the left panel and then choose \"upload file\" icon. Then change the key file path.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import autogen\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    file_location=\"..\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Agents\n",
    "\n",
    "We construct the assistant agent and the user proxy agent. We specify `human_input_mode` as \"TERMINATE\" in the user proxy agent, which will ask for feedback when it receives a \"TERMINATE\" signal from the assistant agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml.autogen import AssistantAgent, UserProxyAgent\n",
    "llm_config = {\n",
    "    \"request_timeout\": 600,\n",
    "    \"seed\": 43,\n",
    "    \"config_list\": config_list,\n",
    "    \"model\": \"gpt-4\",  # make sure the endpoint you use supports the model\n",
    "    \"temperature\": 0,\n",
    "}\n",
    "assistant = AssistantAgent(\n",
    "    name=\"proposer\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"Consider the following puzzle problem:\n",
    "\n",
    "Problem description:\n",
    "- There are three lists labeled A, B, and C.\n",
    "- There are three numbers -- 0, 1, and 2 -- distributed among those three lists.\n",
    "- You can move numbers from the end of one list to the end of another list.\n",
    "Rule #1: You can only move a number if it is at the end of its current list.\n",
    "Rule #2: You can only move a number to the end of a list if it is larger than the other numbers in that list.\n",
    "\n",
    "For a given configuration:\n",
    "1. find the last number in each list and output, e.g.:\n",
    "list A: a = empty\n",
    "list B: b = 1\n",
    "list C: c = 2\n",
    "2. for each pair of lists (A, B), (A, C), (B, C), find which list has the larger number and put it as the source. \n",
    "\n",
    "Example: \n",
    "    list A: a = empty\n",
    "    list B: b = 0\n",
    "    list C: c = 2\n",
    "    (A,B) or (B,A)? a is empty and b is not, so B->A\n",
    "    (A,C) or (C,A)? a is empty and c is not, so C->A\n",
    "    (B,C) or (C,B)? c>b, the list with larger number must be source, so C->B.\n",
    "\n",
    "Example:\n",
    "    list A: a = empty\n",
    "    list B: b = empty\n",
    "    list C: c = 2\n",
    "    (A,B) or (B,A)? a and b are both empty, so skip\n",
    "    (A,C) or (C,A)? a is empty and c is not, so C->A\n",
    "    (B,C) or (C,B)? b is empty and c is not, so C->B.\n",
    "\n",
    "3. Output the state after each candidate move. e.g.,\n",
    "    From the given configuration, the state after (B->A) is (remove b from A and append to B): ...\n",
    "    From the given configuration, the state after (C->B) is (remove c from C and append to B): ...\n",
    "\"\"\",\n",
    ")\n",
    "# create a UserProxyAgent instance named \"user\"\n",
    "user = AssistantAgent(\n",
    "    name=\"user\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=0,\n",
    "    # is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\") or x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE.\"),\n",
    "    # code_execution_config=False,\n",
    "    # llm_config=llm_config,\n",
    "    # system_message=\"\"\"You are a critic. You identify mistakes. If there is no mistake, reply TERMINATE to end the conversation.\"\"\"\n",
    "    # system_message=\"\"\"You verify the solution and ask the user to check the entire sequence in case a step is missing. If the solution is correct, say \"TERMINATE\" to end the conversation.\"\"\",\n",
    "    # system_message=\"\"\"You verify whether a move is valid:\n",
    "    # 1. say the state before a move.\n",
    "    # 2. say the move.\n",
    "    # 3. repeat the rules.\n",
    "    # 4. use the rules to check whether it is valid and whether the result after move is correct. Do not assume a step is valid until you verify it.\"\"\",\n",
    "    # work_dir='hanoi',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to proposer):\n",
      "\n",
      "Current configuration:\n",
      "A = []\n",
      "B = [0, 2]\n",
      "C = [1]\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mproposer\u001b[0m (to user):\n",
      "\n",
      "1. Find the last number in each list:\n",
      "    list A: a = empty\n",
      "    list B: b = 2\n",
      "    list C: c = 1\n",
      "\n",
      "2. For each pair of lists:\n",
      "    (A,B) or (B,A)? a is empty and b is not, so B->A\n",
      "    (A,C) or (C,A)? a is empty and c is not, so C->A\n",
      "    (B,C) or (C,B)? b>c, the list with larger number must be source, so B->C.\n",
      "\n",
      "3. Output the state after each candidate move:\n",
      "    From the given configuration, the state after (B->A) is (remove b from B and append to A): A = [2], B = [0], C = [1]\n",
      "    From the given configuration, the state after (C->A) is (remove c from C and append to A): A = [1], B = [0, 2], C = []\n",
      "    From the given configuration, the state after (B->C) is (remove b from B and append to C): A = [], B = [0], C = [1, 2]\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"Current configuration:\n",
    "A = []\n",
    "B = [0, 2]\n",
    "C = [1]\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to proposer):\n",
      "\n",
      "Current configuration:\n",
      "A = []\n",
      "B = [0, 1]\n",
      "C = [2]\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mproposer\u001b[0m (to user):\n",
      "\n",
      "1. Find the last number in each list:\n",
      "    list A: a = empty\n",
      "    list B: b = 1\n",
      "    list C: c = 2\n",
      "\n",
      "2. For each pair of lists (A, B), (A, C), (B, C), find which list has the larger number and put it as the source:\n",
      "    (A,B) or (B,A)? a is empty and b is not, so B->A\n",
      "    (A,C) or (C,A)? c>a, the list with larger number must be source, so C->A\n",
      "    (B,C) or (C,B)? c>b, the list with larger number must be source, so C->B.\n",
      "\n",
      "3. Output the state after each candidate move:\n",
      "    From the given configuration, the state after (B->A) is (remove b from B and append to A): A = [1], B = [0], C = [2]\n",
      "    From the given configuration, the state after (C->A) is (remove c from C and append to A): A = [2], B = [0, 1], C = []\n",
      "    From the given configuration, the state after (C->B) is (remove c from C and append to B): A = [], B = [0, 1, 2], C = []\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"Current configuration:\n",
    "A = []\n",
    "B = [0, 1]\n",
    "C = [2]\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to proposer):\n",
      "\n",
      "Current configuration:\n",
      "A = [0]\n",
      "B = [1]\n",
      "C = [2]\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mproposer\u001b[0m (to user):\n",
      "\n",
      "1. Find the last number in each list:\n",
      "    list A: a = 0\n",
      "    list B: b = 1\n",
      "    list C: c = 2\n",
      "\n",
      "2. For each pair of lists (A, B), (A, C), (B, C), find which list has the larger number and put it as the source:\n",
      "    (A,B) or (B,A)? b>a, the list with larger number must be source, so B->A\n",
      "    (A,C) or (C,A)? c>a, the list with larger number must be source, so C->A\n",
      "    (B,C) or (C,B)? c>b, the list with larger number must be source, so C->B.\n",
      "\n",
      "3. Output the state after each candidate move:\n",
      "    From the given configuration, the state after (B->A) is (remove b from B and append to A): A = [0, 1], B = [], C = [2]\n",
      "    From the given configuration, the state after (C->A) is (remove c from C and append to A): A = [0, 2], B = [1], C = []\n",
      "    From the given configuration, the state after (C->B) is (remove c from C and append to B): A = [0], B = [1, 2], C = []\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"Current configuration:\n",
    "A = [0]\n",
    "B = [1]\n",
    "C = [2]\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to proposer):\n",
      "\n",
      "Current configuration:\n",
      "A = [0]\n",
      "B = [1, 2]\n",
      "C = []\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mproposer\u001b[0m (to user):\n",
      "\n",
      "1. Find the last number in each list:\n",
      "    list A: a = 0\n",
      "    list B: b = 2\n",
      "    list C: c = empty\n",
      "\n",
      "2. For each pair of lists (A, B), (A, C), (B, C), find which list has the larger number and put it as the source:\n",
      "    (A,B) or (B,A)? b>a, the list with larger number must be source, so B->A\n",
      "    (A,C) or (C,A)? a is not empty and c is empty, so A->C\n",
      "    (B,C) or (C,B)? b is not empty and c is empty, so B->C\n",
      "\n",
      "3. Output the state after each candidate move:\n",
      "    From the given configuration, the state after (B->A) is (remove 2 from B and append to A): A = [0, 2], B = [1], C = []\n",
      "    From the given configuration, the state after (A->C) is (remove 0 from A and append to C): A = [], B = [1, 2], C = [0]\n",
      "    From the given configuration, the state after (B->C) is (remove 2 from B and append to C): A = [0], B = [1], C = [2]\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"Current configuration:\n",
    "A = [0]\n",
    "B = [1, 2]\n",
    "C = []\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to proposer):\n",
      "\n",
      "Current configuration:\n",
      "A = []\n",
      "B = [0, 1, 2]\n",
      "C = []\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mproposer\u001b[0m (to user):\n",
      "\n",
      "1. Find the last number in each list:\n",
      "    list A: a = empty\n",
      "    list B: b = 2\n",
      "    list C: c = empty\n",
      "\n",
      "2. For each pair of lists (A, B), (A, C), (B, C), find which list has the larger number and put it as the source:\n",
      "    (A,B) or (B,A)? a is empty and b is not, so B->A\n",
      "    (A,C) or (C,A)? a and c are both empty, so skip\n",
      "    (B,C) or (C,B)? b is not empty and c is empty, so B->C\n",
      "\n",
      "3. Output the state after each candidate move:\n",
      "    From the given configuration, the state after (B->A) is (remove b from B and append to A): \n",
      "    A = [2]\n",
      "    B = [0, 1]\n",
      "    C = []\n",
      "    \n",
      "    From the given configuration, the state after (B->C) is (remove b from B and append to C): \n",
      "    A = []\n",
      "    B = [0, 1]\n",
      "    C = [2]\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"Current configuration:\n",
    "A = []\n",
    "B = [0, 1, 2]\n",
    "C = []\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to proposer):\n",
      "\n",
      "Current configuration:\n",
      "A = []\n",
      "B = [0, 1, 2]\n",
      "C = [3]\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mproposer\u001b[0m (to user):\n",
      "\n",
      "1. Find the last number in each list:\n",
      "    list A: a = empty\n",
      "    list B: b = 2\n",
      "    list C: c = 3\n",
      "\n",
      "2. For each pair of lists (A, B), (A, C), (B, C), find which list has the larger number and put it as the source:\n",
      "    (A,B) or (B,A)? a is empty and b is not, so B->A\n",
      "    (A,C) or (C,A)? c>a, the list with larger number must be source, so C->A\n",
      "    (B,C) or (C,B)? c>b, the list with larger number must be source, so C->B.\n",
      "\n",
      "3. Output the state after each candidate move:\n",
      "    From the given configuration, the state after (B->A) is (remove b from B and append to A): A = [2], B = [0, 1], C = [3]\n",
      "    From the given configuration, the state after (C->A) is (remove c from C and append to A): A = [3], B = [0, 1, 2], C = []\n",
      "    From the given configuration, the state after (C->B) is (remove c from C and append to B): A = [], B = [0, 1, 2, 3], C = []\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"Current configuration:\n",
    "A = []\n",
    "B = [0, 1, 2]\n",
    "C = [3]\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to proposer):\n",
      "\n",
      "Current configuration:\n",
      "A = [1]\n",
      "B = [0, 2]\n",
      "C = [3]\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mproposer\u001b[0m (to user):\n",
      "\n",
      "1. Find the last number in each list:\n",
      "    list A: a = 1\n",
      "    list B: b = 2\n",
      "    list C: c = 3\n",
      "\n",
      "2. For each pair of lists (A, B), (A, C), (B, C), find which list has the larger number and put it as the source:\n",
      "    (A,B) or (B,A)? b>a, the list with larger number must be source, so B->A\n",
      "    (A,C) or (C,A)? c>a, the list with larger number must be source, so C->A\n",
      "    (B,C) or (C,B)? c>b, the list with larger number must be source, so C->B.\n",
      "\n",
      "3. Output the state after each candidate move:\n",
      "    From the given configuration, the state after (B->A) is (remove 2 from B and append to A): A = [1, 2], B = [0], C = [3]\n",
      "    From the given configuration, the state after (C->A) is (remove 3 from C and append to A): A = [1, 3], B = [0, 2], C = []\n",
      "    From the given configuration, the state after (C->B) is (remove 3 from C and append to B): A = [1], B = [0, 2, 3], C = []\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"Current configuration:\n",
    "A = [1]\n",
    "B = [0, 2]\n",
    "C = [3]\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser\u001b[0m (to proposer):\n",
      "\n",
      "Current configuration:\n",
      "A = [1, 3]\n",
      "B = [0, 2]\n",
      "C = []\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mproposer\u001b[0m (to user):\n",
      "\n",
      "1. Find the last number in each list:\n",
      "    list A: a = 3\n",
      "    list B: b = 2\n",
      "    list C: c = empty\n",
      "\n",
      "2. For each pair of lists (A, B), (A, C), (B, C), find which list has the larger number and put it as the source:\n",
      "    (A,B) or (B,A)? a>b, the list with larger number must be source, so A->B\n",
      "    (A,C) or (C,A)? c is empty and a is not, so A->C\n",
      "    (B,C) or (C,B)? c is empty and b is not, so B->C\n",
      "\n",
      "3. Output the state after each candidate move:\n",
      "    From the given configuration, the state after (A->B) is (remove a from A and append to B): A = [1], B = [0, 2, 3], C = []\n",
      "    From the given configuration, the state after (A->C) is (remove a from A and append to C): A = [1], B = [0, 2], C = [3]\n",
      "    From the given configuration, the state after (B->C) is (remove b from B and append to C): A = [1, 3], B = [0], C = [2]\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"Current configuration:\n",
    "A = [1, 3]\n",
    "B = [0, 2]\n",
    "C = []\n",
    "\"\"\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2d910cfd2d2a4fc49fc30fbbdc5576a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "454146d0f7224f038689031002906e6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e4ae2b6f5a974fd4bafb6abb9d12ff26",
        "IPY_MODEL_577e1e3cc4db4942b0883577b3b52755",
        "IPY_MODEL_b40bdfb1ac1d4cffb7cefcb870c64d45"
       ],
       "layout": "IPY_MODEL_dc83c7bff2f241309537a8119dfc7555",
       "tabbable": null,
       "tooltip": null
      }
     },
     "577e1e3cc4db4942b0883577b3b52755": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d910cfd2d2a4fc49fc30fbbdc5576a7",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_74a6ba0c3cbc4051be0a83e152fe1e62",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "6086462a12d54bafa59d3c4566f06cb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74a6ba0c3cbc4051be0a83e152fe1e62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7d3f3d9e15894d05a4d188ff4f466554": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b40bdfb1ac1d4cffb7cefcb870c64d45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f1355871cc6f4dd4b50d9df5af20e5c8",
       "placeholder": "​",
       "style": "IPY_MODEL_ca245376fd9f4354af6b2befe4af4466",
       "tabbable": null,
       "tooltip": null,
       "value": " 1/1 [00:00&lt;00:00, 44.69it/s]"
      }
     },
     "ca245376fd9f4354af6b2befe4af4466": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dc83c7bff2f241309537a8119dfc7555": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e4ae2b6f5a974fd4bafb6abb9d12ff26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6086462a12d54bafa59d3c4566f06cb2",
       "placeholder": "​",
       "style": "IPY_MODEL_7d3f3d9e15894d05a4d188ff4f466554",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "f1355871cc6f4dd4b50d9df5af20e5c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
