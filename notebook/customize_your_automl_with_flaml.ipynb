{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved. \n",
    "\n",
    "Licensed under the MIT License.\n",
    "\n",
    "# Customize your AutoML with FLAML\n",
    "\n",
    "\n",
    "## Introduction and Preparation\n",
    "\n",
    "This notebook shows you several customization choices you may find useful in FLAML, including customization choices regarding:\n",
    "- **optimization metric**\n",
    "- **learner** and its **search space**\n",
    "- **Resampling strategy**\n",
    "- **Ensemble**\n",
    "\n",
    "### FLAML installation\n",
    "FLAML requires `Python>=3.7`. To run this notebook example, please install flaml with the `notebook` option:\n",
    "```bash\n",
    "pip install flaml[notebook]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install flaml[notebook]==1.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load data and preprocess\n",
    "\n",
    "Download [Airlines dataset](https://www.openml.org/d/1169) from OpenML. The task is to predict whether a given flight will be delayed, given the information of the scheduled departure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset from ./openml_ds1169.pkl\n",
      "Dataset name: airlines\n",
      "X_train.shape: (404537, 7), y_train.shape: (404537,);\n",
      "X_test.shape: (134846, 7), y_test.shape: (134846,)\n"
     ]
    }
   ],
   "source": [
    "from flaml.data import load_openml_dataset\n",
    "X_train, X_test, y_train, y_test = load_openml_dataset(dataset_id=1169, data_dir='./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Optimization Metric\n",
    "\n",
    "It's easy to customize the optimization metric. As an example, we demonstrate with a custom metric function which combines training loss and validation loss as the final loss to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(X_val, y_val, estimator, labels, X_train, y_train,\n",
    "                  weight_val=None, weight_train=None, config=None,\n",
    "                  groups_val=None, groups_train=None):\n",
    "    from sklearn.metrics import log_loss\n",
    "    import time\n",
    "    start = time.time()\n",
    "    y_pred = estimator.predict_proba(X_val)\n",
    "    pred_time = (time.time() - start) / len(X_val)\n",
    "    val_loss = log_loss(y_val, y_pred, labels=labels,\n",
    "                         sample_weight=weight_val)\n",
    "    y_pred = estimator.predict_proba(X_train)\n",
    "    train_loss = log_loss(y_train, y_pred, labels=labels,\n",
    "                          sample_weight=weight_train)\n",
    "    alpha = 0.5\n",
    "    return val_loss * (1 + alpha) - alpha * train_loss, {\n",
    "        \"val_loss\": val_loss, \"train_loss\": train_loss, \"pred_time\": pred_time\n",
    "    }\n",
    "    # two elements are returned:\n",
    "    # the first element is the metric to minimize as a float number,\n",
    "    # the second element is a dictionary of the metrics to log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then pass this custom metric function to automl's `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl.automl: 01-06 15:42:10] {2625} INFO - task = classification\n",
      "[flaml.automl.automl: 01-06 15:42:10] {2627} INFO - Data split method: stratified\n",
      "[flaml.automl.automl: 01-06 15:42:10] {2630} INFO - Evaluation method: holdout\n",
      "[flaml.automl.automl: 01-06 15:42:10] {2757} INFO - Minimizing error metric: customized metric\n",
      "[flaml.automl.automl: 01-06 15:42:10] {2902} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl.automl: 01-06 15:42:10] {3203} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:10] {3340} INFO - Estimated sufficient time budget=25247s. Estimated necessary time budget=582s.\n",
      "[flaml.automl.automl: 01-06 15:42:10] {3387} INFO -  at 0.6s,\testimator lgbm's best error=0.6647,\tbest estimator lgbm's best error=0.6647\n",
      "[flaml.automl.automl: 01-06 15:42:10] {3203} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:10] {3387} INFO -  at 0.6s,\testimator lgbm's best error=0.6647,\tbest estimator lgbm's best error=0.6647\n",
      "[flaml.automl.automl: 01-06 15:42:10] {3203} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:10] {3387} INFO -  at 0.6s,\testimator lgbm's best error=0.6491,\tbest estimator lgbm's best error=0.6491\n",
      "[flaml.automl.automl: 01-06 15:42:10] {3203} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:10] {3387} INFO -  at 0.7s,\testimator lgbm's best error=0.6423,\tbest estimator lgbm's best error=0.6423\n",
      "[flaml.automl.automl: 01-06 15:42:10] {3203} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:11] {3387} INFO -  at 0.8s,\testimator lgbm's best error=0.6423,\tbest estimator lgbm's best error=0.6423\n",
      "[flaml.automl.automl: 01-06 15:42:11] {3203} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:11] {3387} INFO -  at 0.8s,\testimator lgbm's best error=0.6423,\tbest estimator lgbm's best error=0.6423\n",
      "[flaml.automl.automl: 01-06 15:42:11] {3203} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:11] {3387} INFO -  at 0.9s,\testimator lgbm's best error=0.6400,\tbest estimator lgbm's best error=0.6400\n",
      "[flaml.automl.automl: 01-06 15:42:11] {3203} INFO - iteration 7, current learner xgboost\n",
      "/home/qxw5138/miniconda3/envs/tutorial/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "[flaml.automl.automl: 01-06 15:42:11] {3387} INFO -  at 1.4s,\testimator xgboost's best error=0.6845,\tbest estimator lgbm's best error=0.6400\n",
      "[flaml.automl.automl: 01-06 15:42:11] {3203} INFO - iteration 8, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:11] {3387} INFO -  at 1.5s,\testimator extra_tree's best error=0.6678,\tbest estimator lgbm's best error=0.6400\n",
      "[flaml.automl.automl: 01-06 15:42:11] {3203} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:11] {3387} INFO -  at 1.5s,\testimator lgbm's best error=0.6400,\tbest estimator lgbm's best error=0.6400\n",
      "[flaml.automl.automl: 01-06 15:42:11] {3203} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:11] {3387} INFO -  at 1.6s,\testimator lgbm's best error=0.6400,\tbest estimator lgbm's best error=0.6400\n",
      "[flaml.automl.automl: 01-06 15:42:11] {3203} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:11] {3387} INFO -  at 1.7s,\testimator lgbm's best error=0.6400,\tbest estimator lgbm's best error=0.6400\n",
      "[flaml.automl.automl: 01-06 15:42:11] {3203} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:12] {3387} INFO -  at 1.8s,\testimator extra_tree's best error=0.6576,\tbest estimator lgbm's best error=0.6400\n",
      "[flaml.automl.automl: 01-06 15:42:12] {3203} INFO - iteration 13, current learner rf\n",
      "[flaml.automl.automl: 01-06 15:42:12] {3387} INFO -  at 2.0s,\testimator rf's best error=0.6614,\tbest estimator lgbm's best error=0.6400\n",
      "[flaml.automl.automl: 01-06 15:42:12] {3203} INFO - iteration 14, current learner rf\n",
      "[flaml.automl.automl: 01-06 15:42:12] {3387} INFO -  at 2.2s,\testimator rf's best error=0.6523,\tbest estimator lgbm's best error=0.6400\n",
      "[flaml.automl.automl: 01-06 15:42:12] {3203} INFO - iteration 15, current learner xgboost\n",
      "/home/qxw5138/miniconda3/envs/tutorial/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "[flaml.automl.automl: 01-06 15:42:12] {3387} INFO -  at 2.6s,\testimator xgboost's best error=0.6845,\tbest estimator lgbm's best error=0.6400\n",
      "[flaml.automl.automl: 01-06 15:42:12] {3203} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:13] {3387} INFO -  at 2.8s,\testimator lgbm's best error=0.6400,\tbest estimator lgbm's best error=0.6400\n",
      "[flaml.automl.automl: 01-06 15:42:13] {3203} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:13] {3387} INFO -  at 3.0s,\testimator extra_tree's best error=0.6576,\tbest estimator lgbm's best error=0.6400\n",
      "[flaml.automl.automl: 01-06 15:42:13] {3203} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:13] {3387} INFO -  at 3.1s,\testimator lgbm's best error=0.6335,\tbest estimator lgbm's best error=0.6335\n",
      "[flaml.automl.automl: 01-06 15:42:13] {3203} INFO - iteration 19, current learner xgboost\n",
      "/home/qxw5138/miniconda3/envs/tutorial/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "[flaml.automl.automl: 01-06 15:42:13] {3387} INFO -  at 3.5s,\testimator xgboost's best error=0.6728,\tbest estimator lgbm's best error=0.6335\n",
      "[flaml.automl.automl: 01-06 15:42:13] {3203} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:13] {3387} INFO -  at 3.7s,\testimator lgbm's best error=0.6335,\tbest estimator lgbm's best error=0.6335\n",
      "[flaml.automl.automl: 01-06 15:42:13] {3203} INFO - iteration 21, current learner rf\n",
      "[flaml.automl.automl: 01-06 15:42:14] {3387} INFO -  at 3.9s,\testimator rf's best error=0.6523,\tbest estimator lgbm's best error=0.6335\n",
      "[flaml.automl.automl: 01-06 15:42:14] {3203} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:14] {3387} INFO -  at 4.0s,\testimator lgbm's best error=0.6335,\tbest estimator lgbm's best error=0.6335\n",
      "[flaml.automl.automl: 01-06 15:42:14] {3203} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:14] {3387} INFO -  at 4.1s,\testimator lgbm's best error=0.6335,\tbest estimator lgbm's best error=0.6335\n",
      "[flaml.automl.automl: 01-06 15:42:14] {3203} INFO - iteration 24, current learner xgboost\n",
      "/home/qxw5138/miniconda3/envs/tutorial/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "[flaml.automl.automl: 01-06 15:42:14] {3387} INFO -  at 4.6s,\testimator xgboost's best error=0.6486,\tbest estimator lgbm's best error=0.6335\n",
      "[flaml.automl.automl: 01-06 15:42:14] {3203} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:14] {3387} INFO -  at 4.7s,\testimator extra_tree's best error=0.6576,\tbest estimator lgbm's best error=0.6335\n",
      "[flaml.automl.automl: 01-06 15:42:14] {3203} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:15] {3387} INFO -  at 4.8s,\testimator lgbm's best error=0.6335,\tbest estimator lgbm's best error=0.6335\n",
      "[flaml.automl.automl: 01-06 15:42:15] {3203} INFO - iteration 27, current learner xgboost\n",
      "/home/qxw5138/miniconda3/envs/tutorial/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "[flaml.automl.automl: 01-06 15:42:15] {3387} INFO -  at 5.5s,\testimator xgboost's best error=0.6486,\tbest estimator lgbm's best error=0.6335\n",
      "[flaml.automl.automl: 01-06 15:42:15] {3203} INFO - iteration 28, current learner xgboost\n",
      "/home/qxw5138/miniconda3/envs/tutorial/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "[flaml.automl.automl: 01-06 15:42:16] {3387} INFO -  at 5.9s,\testimator xgboost's best error=0.6486,\tbest estimator lgbm's best error=0.6335\n",
      "[flaml.automl.automl: 01-06 15:42:16] {3203} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:16] {3387} INFO -  at 6.1s,\testimator extra_tree's best error=0.6480,\tbest estimator lgbm's best error=0.6335\n",
      "[flaml.automl.automl: 01-06 15:42:16] {3203} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:16] {3387} INFO -  at 6.7s,\testimator lgbm's best error=0.6328,\tbest estimator lgbm's best error=0.6328\n",
      "[flaml.automl.automl: 01-06 15:42:16] {3203} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:17] {3387} INFO -  at 7.4s,\testimator lgbm's best error=0.6241,\tbest estimator lgbm's best error=0.6241\n",
      "[flaml.automl.automl: 01-06 15:42:17] {3203} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:18] {3387} INFO -  at 8.0s,\testimator lgbm's best error=0.6241,\tbest estimator lgbm's best error=0.6241\n",
      "[flaml.automl.automl: 01-06 15:42:18] {3203} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:18] {3387} INFO -  at 8.1s,\testimator extra_tree's best error=0.6480,\tbest estimator lgbm's best error=0.6241\n",
      "[flaml.automl.automl: 01-06 15:42:18] {3203} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:19] {3387} INFO -  at 8.8s,\testimator lgbm's best error=0.6206,\tbest estimator lgbm's best error=0.6206\n",
      "[flaml.automl.automl: 01-06 15:42:19] {3203} INFO - iteration 35, current learner rf\n",
      "[flaml.automl.automl: 01-06 15:42:19] {3387} INFO -  at 8.9s,\testimator rf's best error=0.6523,\tbest estimator lgbm's best error=0.6206\n",
      "[flaml.automl.automl: 01-06 15:42:19] {3203} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:19] {3387} INFO -  at 9.0s,\testimator extra_tree's best error=0.6480,\tbest estimator lgbm's best error=0.6206\n",
      "[flaml.automl.automl: 01-06 15:42:19] {3203} INFO - iteration 37, current learner rf\n",
      "[flaml.automl.automl: 01-06 15:42:19] {3387} INFO -  at 9.1s,\testimator rf's best error=0.6523,\tbest estimator lgbm's best error=0.6206\n",
      "[flaml.automl.automl: 01-06 15:42:19] {3203} INFO - iteration 38, current learner xgboost\n",
      "/home/qxw5138/miniconda3/envs/tutorial/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "[flaml.automl.automl: 01-06 15:42:19] {3387} INFO -  at 9.5s,\testimator xgboost's best error=0.6485,\tbest estimator lgbm's best error=0.6206\n",
      "[flaml.automl.automl: 01-06 15:42:19] {3203} INFO - iteration 39, current learner rf\n",
      "[flaml.automl.automl: 01-06 15:42:19] {3387} INFO -  at 9.6s,\testimator rf's best error=0.6523,\tbest estimator lgbm's best error=0.6206\n",
      "[flaml.automl.automl: 01-06 15:42:19] {3203} INFO - iteration 40, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:19] {3387} INFO -  at 9.7s,\testimator extra_tree's best error=0.6480,\tbest estimator lgbm's best error=0.6206\n",
      "[flaml.automl.automl: 01-06 15:42:19] {3203} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:20] {3387} INFO -  at 9.7s,\testimator extra_tree's best error=0.6480,\tbest estimator lgbm's best error=0.6206\n",
      "[flaml.automl.automl: 01-06 15:42:20] {3203} INFO - iteration 42, current learner rf\n",
      "[flaml.automl.automl: 01-06 15:42:20] {3387} INFO -  at 9.8s,\testimator rf's best error=0.6523,\tbest estimator lgbm's best error=0.6206\n",
      "[flaml.automl.automl: 01-06 15:42:20] {3203} INFO - iteration 43, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:20] {3387} INFO -  at 9.9s,\testimator extra_tree's best error=0.6480,\tbest estimator lgbm's best error=0.6206\n",
      "[flaml.automl.automl: 01-06 15:42:20] {3203} INFO - iteration 44, current learner xgb_limitdepth\n",
      "/home/qxw5138/miniconda3/envs/tutorial/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "[flaml.automl.automl: 01-06 15:42:20] {3387} INFO -  at 10.5s,\testimator xgb_limitdepth's best error=0.6682,\tbest estimator lgbm's best error=0.6206\n",
      "[flaml.automl.automl: 01-06 15:42:21] {3647} INFO - retrain lgbm for 0.6s\n",
      "[flaml.automl.automl: 01-06 15:42:21] {3654} INFO - retrained model: LGBMClassifier(learning_rate=0.8795579359736123, max_bin=1023,\n",
      "               min_child_samples=10, n_estimators=5, num_leaves=67,\n",
      "               reg_alpha=0.0020664375232232334, reg_lambda=11.42182869316027,\n",
      "               verbose=-1)\n",
      "[flaml.automl.automl: 01-06 15:42:21] {2932} INFO - fit succeeded\n",
      "[flaml.automl.automl: 01-06 15:42:21] {2933} INFO - Time taken to find the best model: 8.83951449394226\n"
     ]
    }
   ],
   "source": [
    "''' import AutoML class from flaml package '''\n",
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "settings = {\n",
    "    \"time_budget\": 10,  # total running time in seconds\n",
    "    \"metric\": custom_metric,  # pass the custom metric funtion here\n",
    "    \"task\": 'classification',  # task type\n",
    "    \"log_file_name\": 'airlines_experiment_custom_metric.log',  # flaml log file\n",
    "}\n",
    "\n",
    "automl.fit(X_train=X_train, y_train=y_train, **settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Learner and Search Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some experienced automl users may have a preferred model to tune or may already have a reasonably by-hand-tuned model before launching the automl experiment. They need to select optimal configurations for the customized model mixed with standard built-in learners. \n",
    "\n",
    "FLAML can easily incorporate customized/new learners (preferably with sklearn API) provided by users in a real-time manner, as demonstrated below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example of Regularized Greedy Forest\n",
    "\n",
    "[Regularized Greedy Forest](https://arxiv.org/abs/1109.0887) (RGF) is a machine learning method currently not included in FLAML. The RGF has many tuning parameters, the most critical of which are: `[max_leaf, n_iter, n_tree_search, opt_interval, min_samples_leaf]`. To run a customized/new learner, the user needs to provide the following information:\n",
    "* an implementation of the customized/new learner\n",
    "* a list of hyperparameter names and types\n",
    "* rough ranges of hyperparameters (i.e., upper/lower bounds)\n",
    "* choose initial value corresponding to low cost for cost-related hyperparameters (e.g., initial value for max_leaf and n_iter should be small)\n",
    "\n",
    "In this example, the above information for RGF is wrapped in a python class called *MyRegularizedGreedyForest* that exposes the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install rgf-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "''' SKLearnEstimator is the super class for a sklearn learner '''\n",
    "from flaml.model import SKLearnEstimator\n",
    "from flaml import tune\n",
    "from flaml.data import CLASSIFICATION\n",
    "\n",
    "\n",
    "class MyRegularizedGreedyForest(SKLearnEstimator):\n",
    "    def __init__(self, task='binary', **config):\n",
    "        '''Constructor\n",
    "        \n",
    "        Args:\n",
    "            task: A string of the task type, one of\n",
    "                'binary', 'multiclass', 'regression'\n",
    "            config: A dictionary containing the hyperparameter names\n",
    "                and 'n_jobs' as keys. n_jobs is the number of parallel threads.\n",
    "        '''\n",
    "\n",
    "        super().__init__(task, **config)\n",
    "\n",
    "        '''task=binary or multi for classification task'''\n",
    "        if task in CLASSIFICATION:\n",
    "            from rgf.sklearn import RGFClassifier\n",
    "\n",
    "            self.estimator_class = RGFClassifier\n",
    "        else:\n",
    "            from rgf.sklearn import RGFRegressor\n",
    "            \n",
    "            self.estimator_class = RGFRegressor\n",
    "\n",
    "    @classmethod\n",
    "    def search_space(cls, data_size, task):\n",
    "        '''[required method] search space\n",
    "\n",
    "        Returns:\n",
    "            A dictionary of the search space. \n",
    "            Each key is the name of a hyperparameter, and value is a dict with\n",
    "                its domain (required) and low_cost_init_value, init_value,\n",
    "                cat_hp_cost (if applicable).\n",
    "                e.g.,\n",
    "                {'domain': tune.randint(lower=1, upper=10), 'init_value': 1}.\n",
    "        '''\n",
    "        space = {        \n",
    "            'max_leaf': {'domain': tune.lograndint(lower=4, upper=data_size[0]), 'init_value': 4, 'low_cost_init_value': 4},\n",
    "            'n_iter': {'domain': tune.lograndint(lower=1, upper=data_size[0]), 'init_value': 1, 'low_cost_init_value': 1},\n",
    "            'n_tree_search': {'domain': tune.lograndint(lower=1, upper=32768), 'init_value': 1, 'low_cost_init_value': 1},\n",
    "            'opt_interval': {'domain': tune.lograndint(lower=1, upper=10000), 'init_value': 100},\n",
    "            'learning_rate': {'domain': tune.loguniform(lower=0.01, upper=20.0)},\n",
    "            'min_samples_leaf': {'domain': tune.lograndint(lower=1, upper=20), 'init_value': 20},\n",
    "        }\n",
    "        return space\n",
    "\n",
    "    @classmethod\n",
    "    def size(cls, config):\n",
    "        '''[optional method] memory size of the estimator in bytes\n",
    "        \n",
    "        Args:\n",
    "            config - the dict of the hyperparameter config\n",
    "\n",
    "        Returns:\n",
    "            A float of the memory size required by the estimator to train the\n",
    "            given config\n",
    "        '''\n",
    "        max_leaves = int(round(config['max_leaf']))\n",
    "        n_estimators = int(round(config['n_iter']))\n",
    "        return (max_leaves * 3 + (max_leaves - 1) * 4 + 1.0) * n_estimators * 8\n",
    "\n",
    "    @classmethod\n",
    "    def cost_relative2lgbm(cls):\n",
    "        '''[optional method] relative cost compared to lightgbm\n",
    "        '''\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Add Customized Learner and Run FLAML AutoML\n",
    "\n",
    "After adding RGF into the list of learners, we run automl by tuning hyperpameters of RGF as well as the default learners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "automl = AutoML()\n",
    "automl.add_learner(learner_name='RGF', learner_class=MyRegularizedGreedyForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl.automl: 01-06 15:42:23] {2625} INFO - task = classification\n",
      "[flaml.automl.automl: 01-06 15:42:23] {2627} INFO - Data split method: stratified\n",
      "[flaml.automl.automl: 01-06 15:42:23] {2630} INFO - Evaluation method: holdout\n",
      "[flaml.automl.automl: 01-06 15:42:23] {2757} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl.automl: 01-06 15:42:23] {2902} INFO - List of ML learners in AutoML Run: ['RGF', 'lgbm', 'rf', 'xgboost']\n",
      "[flaml.automl.automl: 01-06 15:42:23] {3203} INFO - iteration 0, current learner RGF\n",
      "/home/qxw5138/miniconda3/envs/tutorial/lib/python3.8/site-packages/rgf/utils.py:224: UserWarning: Cannot find FastRGF executable files. FastRGF estimators will be unavailable for usage.\n",
      "  warnings.warn(\"Cannot find FastRGF executable files. \"\n",
      "[flaml.automl.automl: 01-06 15:42:24] {3340} INFO - Estimated sufficient time budget=354648s. Estimated necessary time budget=355s.\n",
      "[flaml.automl.automl: 01-06 15:42:24] {3387} INFO -  at 1.4s,\testimator RGF's best error=0.3840,\tbest estimator RGF's best error=0.3840\n",
      "[flaml.automl.automl: 01-06 15:42:24] {3203} INFO - iteration 1, current learner RGF\n",
      "[flaml.automl.automl: 01-06 15:42:25] {3387} INFO -  at 2.0s,\testimator RGF's best error=0.3840,\tbest estimator RGF's best error=0.3840\n",
      "[flaml.automl.automl: 01-06 15:42:25] {3203} INFO - iteration 2, current learner RGF\n",
      "[flaml.automl.automl: 01-06 15:42:25] {3387} INFO -  at 2.5s,\testimator RGF's best error=0.3840,\tbest estimator RGF's best error=0.3840\n",
      "[flaml.automl.automl: 01-06 15:42:25] {3203} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:25] {3387} INFO -  at 2.5s,\testimator lgbm's best error=0.3777,\tbest estimator lgbm's best error=0.3777\n",
      "[flaml.automl.automl: 01-06 15:42:25] {3203} INFO - iteration 4, current learner RGF\n",
      "[flaml.automl.automl: 01-06 15:42:26] {3387} INFO -  at 3.0s,\testimator RGF's best error=0.3840,\tbest estimator lgbm's best error=0.3777\n",
      "[flaml.automl.automl: 01-06 15:42:26] {3203} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:26] {3387} INFO -  at 3.1s,\testimator lgbm's best error=0.3777,\tbest estimator lgbm's best error=0.3777\n",
      "[flaml.automl.automl: 01-06 15:42:26] {3203} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:26] {3387} INFO -  at 3.1s,\testimator lgbm's best error=0.3777,\tbest estimator lgbm's best error=0.3777\n",
      "[flaml.automl.automl: 01-06 15:42:26] {3203} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:26] {3387} INFO -  at 3.2s,\testimator lgbm's best error=0.3661,\tbest estimator lgbm's best error=0.3661\n",
      "[flaml.automl.automl: 01-06 15:42:26] {3203} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:26] {3387} INFO -  at 3.2s,\testimator lgbm's best error=0.3661,\tbest estimator lgbm's best error=0.3661\n",
      "[flaml.automl.automl: 01-06 15:42:26] {3203} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:26] {3387} INFO -  at 3.3s,\testimator lgbm's best error=0.3633,\tbest estimator lgbm's best error=0.3633\n",
      "[flaml.automl.automl: 01-06 15:42:26] {3203} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:26] {3387} INFO -  at 3.3s,\testimator lgbm's best error=0.3633,\tbest estimator lgbm's best error=0.3633\n",
      "[flaml.automl.automl: 01-06 15:42:26] {3203} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:26] {3387} INFO -  at 3.3s,\testimator lgbm's best error=0.3633,\tbest estimator lgbm's best error=0.3633\n",
      "[flaml.automl.automl: 01-06 15:42:26] {3203} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:26] {3387} INFO -  at 3.5s,\testimator lgbm's best error=0.3613,\tbest estimator lgbm's best error=0.3613\n",
      "[flaml.automl.automl: 01-06 15:42:26] {3203} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:27] {3387} INFO -  at 3.5s,\testimator lgbm's best error=0.3613,\tbest estimator lgbm's best error=0.3613\n",
      "[flaml.automl.automl: 01-06 15:42:27] {3203} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:27] {3387} INFO -  at 3.8s,\testimator lgbm's best error=0.3581,\tbest estimator lgbm's best error=0.3581\n",
      "[flaml.automl.automl: 01-06 15:42:27] {3203} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:27] {3387} INFO -  at 4.0s,\testimator lgbm's best error=0.3581,\tbest estimator lgbm's best error=0.3581\n",
      "[flaml.automl.automl: 01-06 15:42:27] {3203} INFO - iteration 16, current learner RGF\n",
      "[flaml.automl.automl: 01-06 15:42:27] {3387} INFO -  at 4.5s,\testimator RGF's best error=0.3840,\tbest estimator lgbm's best error=0.3581\n",
      "[flaml.automl.automl: 01-06 15:42:28] {3203} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:28] {3387} INFO -  at 4.6s,\testimator lgbm's best error=0.3581,\tbest estimator lgbm's best error=0.3581\n",
      "[flaml.automl.automl: 01-06 15:42:28] {3203} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:28] {3387} INFO -  at 4.9s,\testimator lgbm's best error=0.3581,\tbest estimator lgbm's best error=0.3581\n",
      "[flaml.automl.automl: 01-06 15:42:28] {3203} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:28] {3387} INFO -  at 5.0s,\testimator lgbm's best error=0.3581,\tbest estimator lgbm's best error=0.3581\n",
      "[flaml.automl.automl: 01-06 15:42:28] {3203} INFO - iteration 20, current learner RGF\n",
      "[flaml.automl.automl: 01-06 15:42:29] {3387} INFO -  at 5.6s,\testimator RGF's best error=0.3766,\tbest estimator lgbm's best error=0.3581\n",
      "[flaml.automl.automl: 01-06 15:42:29] {3203} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:29] {3387} INFO -  at 5.6s,\testimator lgbm's best error=0.3581,\tbest estimator lgbm's best error=0.3581\n",
      "[flaml.automl.automl: 01-06 15:42:29] {3203} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:29] {3387} INFO -  at 5.8s,\testimator lgbm's best error=0.3581,\tbest estimator lgbm's best error=0.3581\n",
      "[flaml.automl.automl: 01-06 15:42:29] {3203} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:29] {3387} INFO -  at 5.9s,\testimator lgbm's best error=0.3581,\tbest estimator lgbm's best error=0.3581\n",
      "[flaml.automl.automl: 01-06 15:42:29] {3203} INFO - iteration 24, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:29] {3387} INFO -  at 6.0s,\testimator lgbm's best error=0.3581,\tbest estimator lgbm's best error=0.3581\n",
      "[flaml.automl.automl: 01-06 15:42:29] {3203} INFO - iteration 25, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:29] {3387} INFO -  at 6.4s,\testimator lgbm's best error=0.3574,\tbest estimator lgbm's best error=0.3574\n",
      "[flaml.automl.automl: 01-06 15:42:29] {3203} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:30] {3387} INFO -  at 6.7s,\testimator lgbm's best error=0.3555,\tbest estimator lgbm's best error=0.3555\n",
      "[flaml.automl.automl: 01-06 15:42:30] {3203} INFO - iteration 27, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:30] {3387} INFO -  at 7.0s,\testimator lgbm's best error=0.3555,\tbest estimator lgbm's best error=0.3555\n",
      "[flaml.automl.automl: 01-06 15:42:30] {3203} INFO - iteration 28, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:30] {3387} INFO -  at 7.2s,\testimator lgbm's best error=0.3555,\tbest estimator lgbm's best error=0.3555\n",
      "[flaml.automl.automl: 01-06 15:42:30] {3203} INFO - iteration 29, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:30] {3387} INFO -  at 7.4s,\testimator lgbm's best error=0.3555,\tbest estimator lgbm's best error=0.3555\n",
      "[flaml.automl.automl: 01-06 15:42:30] {3203} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:31] {3387} INFO -  at 7.6s,\testimator lgbm's best error=0.3555,\tbest estimator lgbm's best error=0.3555\n",
      "[flaml.automl.automl: 01-06 15:42:31] {3203} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:31] {3387} INFO -  at 7.7s,\testimator lgbm's best error=0.3542,\tbest estimator lgbm's best error=0.3542\n",
      "[flaml.automl.automl: 01-06 15:42:31] {3203} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:31] {3387} INFO -  at 7.9s,\testimator lgbm's best error=0.3542,\tbest estimator lgbm's best error=0.3542\n",
      "[flaml.automl.automl: 01-06 15:42:31] {3203} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:31] {3387} INFO -  at 8.0s,\testimator lgbm's best error=0.3542,\tbest estimator lgbm's best error=0.3542\n",
      "[flaml.automl.automl: 01-06 15:42:31] {3203} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:31] {3387} INFO -  at 8.1s,\testimator lgbm's best error=0.3542,\tbest estimator lgbm's best error=0.3542\n",
      "[flaml.automl.automl: 01-06 15:42:31] {3203} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:31] {3387} INFO -  at 8.2s,\testimator lgbm's best error=0.3542,\tbest estimator lgbm's best error=0.3542\n",
      "[flaml.automl.automl: 01-06 15:42:31] {3203} INFO - iteration 36, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:31] {3387} INFO -  at 8.3s,\testimator lgbm's best error=0.3542,\tbest estimator lgbm's best error=0.3542\n",
      "[flaml.automl.automl: 01-06 15:42:31] {3203} INFO - iteration 37, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:31] {3387} INFO -  at 8.3s,\testimator lgbm's best error=0.3542,\tbest estimator lgbm's best error=0.3542\n",
      "[flaml.automl.automl: 01-06 15:42:31] {3203} INFO - iteration 38, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:31] {3387} INFO -  at 8.4s,\testimator lgbm's best error=0.3542,\tbest estimator lgbm's best error=0.3542\n",
      "[flaml.automl.automl: 01-06 15:42:31] {3203} INFO - iteration 39, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:34] {3387} INFO -  at 10.6s,\testimator lgbm's best error=0.3425,\tbest estimator lgbm's best error=0.3425\n",
      "[flaml.automl.automl: 01-06 15:42:35] {3647} INFO - retrain lgbm for 1.3s\n",
      "[flaml.automl.automl: 01-06 15:42:35] {3654} INFO - retrained model: LGBMClassifier(colsample_bytree=0.604348197418166,\n",
      "               learning_rate=0.4940639534743911, max_bin=1023,\n",
      "               min_child_samples=7, n_estimators=64, num_leaves=26,\n",
      "               reg_alpha=0.001128891719972783, reg_lambda=0.0017122500086174963,\n",
      "               verbose=-1)\n",
      "[flaml.automl.automl: 01-06 15:42:35] {2932} INFO - fit succeeded\n",
      "[flaml.automl.automl: 01-06 15:42:35] {2933} INFO - Time taken to find the best model: 10.563202857971191\n"
     ]
    }
   ],
   "source": [
    "settings = {\n",
    "    \"time_budget\": 10,  # total running time in seconds\n",
    "    \"metric\": 'accuracy', \n",
    "    \"estimator_list\": ['RGF', 'lgbm', 'rf', 'xgboost'],  # list of ML learners\n",
    "    \"task\": 'classification',  # task type    \n",
    "    \"log_file_name\": 'airlines_experiment_custom_learner.log',  # flaml log file \n",
    "    \"log_training_metric\": True,  # whether to log training metric\n",
    "}\n",
    "\n",
    "automl.fit(X_train=X_train, y_train=y_train, **settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Resembling Strategy\n",
    "Keyword arguments related to resampling strategy in FLAML\n",
    "* `eval_method`\n",
    "* `split_ratio`\n",
    "* `n_splits`\n",
    "* `split_type`\n",
    "* `X_val`, and `y_val`\n",
    "\n",
    "Please find a detailed documention on them in this [page](https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML/#resampling-strategy). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ensemble\n",
    "To use [stacked ensemble after the model search in FLAML](https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML#ensemble) , set `ensemble` to True or a dict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl.automl: 01-06 15:42:35] {2625} INFO - task = classification\n",
      "[flaml.automl.automl: 01-06 15:42:35] {2627} INFO - Data split method: stratified\n",
      "[flaml.automl.automl: 01-06 15:42:35] {2630} INFO - Evaluation method: holdout\n",
      "[flaml.automl.automl: 01-06 15:42:35] {2757} INFO - Minimizing error metric: 1-roc_auc\n",
      "[flaml.automl.automl: 01-06 15:42:35] {2902} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl.automl: 01-06 15:42:35] {3203} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:35] {3340} INFO - Estimated sufficient time budget=12146s. Estimated necessary time budget=280s.\n",
      "[flaml.automl.automl: 01-06 15:42:35] {3387} INFO -  at 0.4s,\testimator lgbm's best error=0.3580,\tbest estimator lgbm's best error=0.3580\n",
      "[flaml.automl.automl: 01-06 15:42:35] {3203} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:35] {3387} INFO -  at 0.5s,\testimator lgbm's best error=0.3580,\tbest estimator lgbm's best error=0.3580\n",
      "[flaml.automl.automl: 01-06 15:42:35] {3203} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:35] {3387} INFO -  at 0.5s,\testimator lgbm's best error=0.3370,\tbest estimator lgbm's best error=0.3370\n",
      "[flaml.automl.automl: 01-06 15:42:35] {3203} INFO - iteration 3, current learner xgboost\n",
      "/home/qxw5138/miniconda3/envs/tutorial/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "[flaml.automl.automl: 01-06 15:42:36] {3387} INFO -  at 0.9s,\testimator xgboost's best error=0.3686,\tbest estimator lgbm's best error=0.3370\n",
      "[flaml.automl.automl: 01-06 15:42:36] {3203} INFO - iteration 4, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:36] {3387} INFO -  at 1.2s,\testimator extra_tree's best error=0.4020,\tbest estimator lgbm's best error=0.3370\n",
      "[flaml.automl.automl: 01-06 15:42:36] {3203} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:36] {3387} INFO -  at 1.2s,\testimator lgbm's best error=0.3276,\tbest estimator lgbm's best error=0.3276\n",
      "[flaml.automl.automl: 01-06 15:42:36] {3203} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:36] {3387} INFO -  at 1.3s,\testimator lgbm's best error=0.3276,\tbest estimator lgbm's best error=0.3276\n",
      "[flaml.automl.automl: 01-06 15:42:36] {3203} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:36] {3387} INFO -  at 1.3s,\testimator lgbm's best error=0.3254,\tbest estimator lgbm's best error=0.3254\n",
      "[flaml.automl.automl: 01-06 15:42:36] {3203} INFO - iteration 8, current learner rf\n",
      "[flaml.automl.automl: 01-06 15:42:36] {3387} INFO -  at 1.5s,\testimator rf's best error=0.3627,\tbest estimator lgbm's best error=0.3254\n",
      "[flaml.automl.automl: 01-06 15:42:36] {3203} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:36] {3387} INFO -  at 1.6s,\testimator lgbm's best error=0.3254,\tbest estimator lgbm's best error=0.3254\n",
      "[flaml.automl.automl: 01-06 15:42:36] {3203} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:37] {3387} INFO -  at 1.6s,\testimator lgbm's best error=0.3254,\tbest estimator lgbm's best error=0.3254\n",
      "[flaml.automl.automl: 01-06 15:42:37] {3203} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:37] {3387} INFO -  at 1.7s,\testimator lgbm's best error=0.3223,\tbest estimator lgbm's best error=0.3223\n",
      "[flaml.automl.automl: 01-06 15:42:37] {3203} INFO - iteration 12, current learner rf\n",
      "[flaml.automl.automl: 01-06 15:42:37] {3387} INFO -  at 1.9s,\testimator rf's best error=0.3487,\tbest estimator lgbm's best error=0.3223\n",
      "[flaml.automl.automl: 01-06 15:42:37] {3203} INFO - iteration 13, current learner rf\n",
      "[flaml.automl.automl: 01-06 15:42:37] {3387} INFO -  at 2.0s,\testimator rf's best error=0.3487,\tbest estimator lgbm's best error=0.3223\n",
      "[flaml.automl.automl: 01-06 15:42:37] {3203} INFO - iteration 14, current learner rf\n",
      "[flaml.automl.automl: 01-06 15:42:37] {3387} INFO -  at 2.2s,\testimator rf's best error=0.3487,\tbest estimator lgbm's best error=0.3223\n",
      "[flaml.automl.automl: 01-06 15:42:37] {3203} INFO - iteration 15, current learner xgboost\n",
      "/home/qxw5138/miniconda3/envs/tutorial/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "[flaml.automl.automl: 01-06 15:42:38] {3387} INFO -  at 2.6s,\testimator xgboost's best error=0.3686,\tbest estimator lgbm's best error=0.3223\n",
      "[flaml.automl.automl: 01-06 15:42:38] {3203} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:38] {3387} INFO -  at 2.7s,\testimator lgbm's best error=0.3223,\tbest estimator lgbm's best error=0.3223\n",
      "[flaml.automl.automl: 01-06 15:42:38] {3203} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:38] {3387} INFO -  at 2.8s,\testimator extra_tree's best error=0.3617,\tbest estimator lgbm's best error=0.3223\n",
      "[flaml.automl.automl: 01-06 15:42:38] {3203} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:38] {3387} INFO -  at 3.1s,\testimator lgbm's best error=0.3223,\tbest estimator lgbm's best error=0.3223\n",
      "[flaml.automl.automl: 01-06 15:42:38] {3203} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:38] {3387} INFO -  at 3.2s,\testimator extra_tree's best error=0.3617,\tbest estimator lgbm's best error=0.3223\n",
      "[flaml.automl.automl: 01-06 15:42:38] {3203} INFO - iteration 20, current learner xgboost\n",
      "/home/qxw5138/miniconda3/envs/tutorial/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "[flaml.automl.automl: 01-06 15:42:39] {3387} INFO -  at 3.7s,\testimator xgboost's best error=0.3686,\tbest estimator lgbm's best error=0.3223\n",
      "[flaml.automl.automl: 01-06 15:42:39] {3203} INFO - iteration 21, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:39] {3387} INFO -  at 3.8s,\testimator extra_tree's best error=0.3617,\tbest estimator lgbm's best error=0.3223\n",
      "[flaml.automl.automl: 01-06 15:42:39] {3203} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:39] {3387} INFO -  at 3.9s,\testimator lgbm's best error=0.3223,\tbest estimator lgbm's best error=0.3223\n",
      "[flaml.automl.automl: 01-06 15:42:39] {3203} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:39] {3387} INFO -  at 4.1s,\testimator lgbm's best error=0.3105,\tbest estimator lgbm's best error=0.3105\n",
      "[flaml.automl.automl: 01-06 15:42:39] {3203} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:39] {3387} INFO -  at 4.3s,\testimator extra_tree's best error=0.3369,\tbest estimator lgbm's best error=0.3105\n",
      "[flaml.automl.automl: 01-06 15:42:39] {3203} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:39] {3387} INFO -  at 4.4s,\testimator extra_tree's best error=0.3369,\tbest estimator lgbm's best error=0.3105\n",
      "[flaml.automl.automl: 01-06 15:42:39] {3203} INFO - iteration 26, current learner rf\n",
      "[flaml.automl.automl: 01-06 15:42:40] {3387} INFO -  at 4.6s,\testimator rf's best error=0.3370,\tbest estimator lgbm's best error=0.3105\n",
      "[flaml.automl.automl: 01-06 15:42:40] {3203} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:40] {3387} INFO -  at 4.7s,\testimator extra_tree's best error=0.3363,\tbest estimator lgbm's best error=0.3105\n",
      "[flaml.automl.automl: 01-06 15:42:40] {3203} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:40] {3387} INFO -  at 4.9s,\testimator extra_tree's best error=0.3343,\tbest estimator lgbm's best error=0.3105\n",
      "[flaml.automl.automl: 01-06 15:42:40] {3203} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:40] {3387} INFO -  at 5.0s,\testimator extra_tree's best error=0.3343,\tbest estimator lgbm's best error=0.3105\n",
      "[flaml.automl.automl: 01-06 15:42:40] {3203} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:40] {3387} INFO -  at 5.3s,\testimator lgbm's best error=0.3081,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:40] {3203} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:41] {3387} INFO -  at 5.6s,\testimator lgbm's best error=0.3081,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:41] {3203} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:41] {3387} INFO -  at 5.9s,\testimator lgbm's best error=0.3081,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:41] {3203} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:41] {3387} INFO -  at 6.0s,\testimator extra_tree's best error=0.3343,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:41] {3203} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:41] {3387} INFO -  at 6.3s,\testimator lgbm's best error=0.3081,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:41] {3203} INFO - iteration 35, current learner xgboost\n",
      "/home/qxw5138/miniconda3/envs/tutorial/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "[flaml.automl.automl: 01-06 15:42:42] {3387} INFO -  at 6.8s,\testimator xgboost's best error=0.3686,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:42] {3203} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:42] {3387} INFO -  at 6.9s,\testimator extra_tree's best error=0.3343,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:42] {3203} INFO - iteration 37, current learner xgboost\n",
      "/home/qxw5138/miniconda3/envs/tutorial/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "[flaml.automl.automl: 01-06 15:42:42] {3387} INFO -  at 7.5s,\testimator xgboost's best error=0.3410,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:42] {3203} INFO - iteration 38, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:43] {3387} INFO -  at 7.6s,\testimator extra_tree's best error=0.3343,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:43] {3203} INFO - iteration 39, current learner rf\n",
      "[flaml.automl.automl: 01-06 15:42:43] {3387} INFO -  at 7.7s,\testimator rf's best error=0.3370,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:43] {3203} INFO - iteration 40, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:43] {3387} INFO -  at 7.8s,\testimator extra_tree's best error=0.3343,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:43] {3203} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:43] {3387} INFO -  at 8.0s,\testimator extra_tree's best error=0.3268,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:43] {3203} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:43] {3387} INFO -  at 8.1s,\testimator lgbm's best error=0.3081,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:43] {3203} INFO - iteration 43, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:43] {3387} INFO -  at 8.3s,\testimator extra_tree's best error=0.3236,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:43] {3203} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:43] {3387} INFO -  at 8.5s,\testimator extra_tree's best error=0.3236,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:43] {3203} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3387} INFO -  at 8.7s,\testimator extra_tree's best error=0.3218,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3203} INFO - iteration 46, current learner rf\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3387} INFO -  at 8.8s,\testimator rf's best error=0.3370,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3203} INFO - iteration 47, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3387} INFO -  at 9.0s,\testimator extra_tree's best error=0.3218,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3203} INFO - iteration 48, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3387} INFO -  at 9.0s,\testimator lgbm's best error=0.3081,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3203} INFO - iteration 49, current learner rf\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3387} INFO -  at 9.1s,\testimator rf's best error=0.3370,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3203} INFO - iteration 50, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3387} INFO -  at 9.2s,\testimator extra_tree's best error=0.3218,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3203} INFO - iteration 51, current learner rf\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3387} INFO -  at 9.3s,\testimator rf's best error=0.3370,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3203} INFO - iteration 52, current learner rf\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3387} INFO -  at 9.4s,\testimator rf's best error=0.3370,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3203} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3387} INFO -  at 9.5s,\testimator lgbm's best error=0.3081,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3203} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3387} INFO -  at 9.5s,\testimator lgbm's best error=0.3081,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:44] {3203} INFO - iteration 55, current learner extra_tree\n",
      "[flaml.automl.automl: 01-06 15:42:45] {3387} INFO -  at 9.6s,\testimator extra_tree's best error=0.3218,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:45] {3203} INFO - iteration 56, current learner rf\n",
      "[flaml.automl.automl: 01-06 15:42:45] {3387} INFO -  at 9.7s,\testimator rf's best error=0.3370,\tbest estimator lgbm's best error=0.3081\n",
      "[flaml.automl.automl: 01-06 15:42:45] {3537} INFO - [('lgbm', {'n_jobs': -1, 'n_estimators': 89, 'num_leaves': 4, 'min_child_samples': 3, 'learning_rate': 0.7804854913819614, 'colsample_bytree': 0.8291836310024803, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.03309807349440701, 'max_bin': 511, 'verbose': -1}), ('extra_tree', {'n_jobs': -1, 'n_estimators': 4, 'max_features': 0.5827542365209447, 'criterion': 'gini', 'max_leaf_nodes': 387, 'random_state': 12032022, 'verbose': 0}), ('rf', {'n_jobs': -1, 'n_estimators': 4, 'max_features': 0.555535403171663, 'criterion': 'gini', 'max_leaf_nodes': 16, 'random_state': 12032022, 'verbose': 0}), ('xgboost', {'n_jobs': -1, 'n_estimators': 4, 'max_leaves': 8, 'min_child_weight': 0.14067525759228752, 'learning_rate': 0.02577572447226278, 'subsample': 1.0, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.6485964803996215, 'max_depth': 0, 'grow_policy': 'lossguide', 'tree_method': 'hist', 'use_label_encoder': False, 'verbosity': 0})]\n",
      "[flaml.automl.automl: 01-06 15:42:45] {3587} INFO - Building ensemble with tuned estimators\n",
      "/home/qxw5138/miniconda3/envs/tutorial/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/home/qxw5138/miniconda3/envs/tutorial/lib/python3.8/site-packages/xgboost/sklearn.py:1421: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "[flaml.automl.automl: 01-06 15:43:22] {3593} INFO - ensemble: StackingClassifier(estimators=[('lgbm',\n",
      "                                <flaml.automl.model.LGBMEstimator object at 0x7f89a2f25550>),\n",
      "                               ('extra_tree',\n",
      "                                <flaml.automl.model.ExtraTreesEstimator object at 0x7f89a2f4d730>),\n",
      "                               ('rf',\n",
      "                                <flaml.automl.model.RandomForestEstimator object at 0x7f89a2f4dee0>),\n",
      "                               ('xgboost',\n",
      "                                <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f89a2f4d700>)],\n",
      "                   final_estimator=LogisticRegression(), n_jobs=1)\n",
      "[flaml.automl.automl: 01-06 15:43:22] {2932} INFO - fit succeeded\n",
      "[flaml.automl.automl: 01-06 15:43:22] {2933} INFO - Time taken to find the best model: 5.324786186218262\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "automl = AutoML()\n",
    "settings = {\n",
    "    \"time_budget\": 10,  # total running time in seconds\n",
    "    \"ensemble\": {\n",
    "        \"final_estimator\": LogisticRegression(),\n",
    "        \"passthrough\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "automl.fit(X_train=X_train, y_train=y_train, **settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Adding extra fit arguments\n",
    "You can specify the different arguments needed by different estimators using the `fit_kwargs_by_estimator` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install flaml[catboost]==1.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml.automl.data import load_openml_dataset\n",
    "from flaml import AutoML\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_openml_dataset(dataset_id=1169, data_dir=\"./\")\n",
    "\n",
    "automl = AutoML()\n",
    "automl_settings = {\n",
    "    \"task\": \"classification\",\n",
    "    \"time_budget\": 10,\n",
    "    \"estimator_list\": [\"catboost\", \"rf\"],\n",
    "    \"fit_kwargs_by_estimator\": {\n",
    "        \"catboost\": {\n",
    "            \"verbose\": True,  # setting the verbosity of catboost to True\n",
    "        }\n",
    "    },\n",
    "}\n",
    "automl.fit(X_train=X_train, y_train=y_train, **automl_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interested in Knowing More?\n",
    "Find more about available customization choices about FLAML's `AuotML` module [here](https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML#customize-automlfit), and about FLAML's `Tune` module [here](https://microsoft.github.io/FLAML/docs/Use-Cases/Tune-User-Defined-Function#advanced-tuning-options). "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51fa32191b42610ce39043fe356a529f3eac32247e42dfb205e9a40779a0304a"
  },
  "kernelspec": {
   "display_name": "tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
